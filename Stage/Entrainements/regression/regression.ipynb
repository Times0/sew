{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "import torch.optim\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import numbers\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import random\n",
    "import csv\n",
    "import seaborn as sn\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'dataset' # name of dataset (with subfolder 'train', 'val', 'test')\n",
    "results_dir = 'test'\n",
    "overwrite = False\n",
    "\n",
    "padded_w, padded_h = 224, 224 # size image in input of model\n",
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "freeze = False # freeze all layers other that modified ones (end fully connected layers)\n",
    "\n",
    "# select optimizer and params\n",
    "optim = 'SGD' # SGD, ADAM\n",
    "lr = 0.01\n",
    "\n",
    "# Select loss function and params\n",
    "loss_f = 'MSE' # MAE, MSE or Huber\n",
    "delta = 2 # only for Huber loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "splits = []\n",
    "for split in ['test', 'val', 'train']:\n",
    "    if split in os.listdir(data_dir):\n",
    "        splits .append(split)\n",
    "\n",
    "if loss_f is not 'Huber':\n",
    "    delta = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspection of Data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json(path):\n",
    "    fname = glob('*.json', dir_fd=path)[0]\n",
    "    with open(os.path.join(path, fname)) as json_f:\n",
    "        json_data = json.load(json_f)\n",
    "        labels = list(json_data.values())\n",
    "    return labels\n",
    "colors = ['red', 'lime']\n",
    "labels = ['train', 'val']\n",
    "data_train = parse_json(os.path.join('dataset', 'train'))\n",
    "data_val = parse_json(os.path.join('dataset', 'val'))\n",
    "bins = np.linspace(min(data_train), max(data_train), max(data_train))\n",
    "plt.style.use('ggplot')\n",
    "plt.hist((data_train, data_val), bins, color = colors, label = labels)\n",
    "plt.legend(prop={'size': 10})\n",
    "plt.title('label repartition')\n",
    "plt.xlabel('number of boxes on image')\n",
    "plt.ylabel('instances')\n",
    "plt.show()\n",
    "import statistics\n",
    "print('moyenne train: ', statistics.mean(data_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "summary(model, input_size=(16, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modified model for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc.in_features # last layer input size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify last fully connected layer (was for classification) to have a regression head\n",
    "model.fc = nn.Sequential( \n",
    "    nn.Linear(512, 1024),\n",
    "    nn.BatchNorm1d(1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024, 1024),\n",
    "    nn.BatchNorm1d(1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 1)\n",
    ")\n",
    "with torch.no_grad():\n",
    "    print(model.fc[-1].bias.shape)\n",
    "    model.fc[-1].bias = nn.Parameter(torch.full(model.fc[-1].bias.shape,3.0))\n",
    "    print(model.fc[-1].bias)\n",
    "# gel des couches\n",
    "if freeze:\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for param in model.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "summary(model, input_size=(16, 3, 224, 224))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "        transforms.Resize((padded_h, padded_w)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_dir, split='train', transform=None):\n",
    "        self.data_dir = os.path.join(data_dir, split)\n",
    "        self.transform = transform\n",
    "        self.image_files = [file for file in os.listdir(self.data_dir) if file.endswith('.jpg') or file.endswith('.jpeg')]\n",
    "        self.labels = self.parse_json()\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.data_dir, self.image_files[idx])\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        label = self.labels[self.image_files[idx]]\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        images_zip, labels_zip = zip(*batch)\n",
    "        images_batch = torch.stack(images_zip, dim = 0)\n",
    "        labels_batch = torch.stack(labels_zip, dim = 0)\n",
    "        return (images_batch, labels_batch)\n",
    "    \n",
    "    def parse_json(self):\n",
    "        fname = glob('*.json', dir_fd=self.data_dir)[0]\n",
    "        with open(os.path.join(self.data_dir, fname)) as json_f:\n",
    "            labels = json.load(json_f)\n",
    "        return labels\n",
    "\n",
    "# dict with the dataloaders\n",
    "dataloaders = {}\n",
    "for split in splits:\n",
    "    dataset = MyDataset(data_dir = data_dir, split = split, transform = data_transforms)\n",
    "    dataloaders[split] = DataLoader(dataset=dataset, shuffle=True, batch_size = batch_size, collate_fn = dataset.collate_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dossier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not overwrite:\n",
    "    k = 0\n",
    "    while os.path.isdir(results_dir+str(k)):\n",
    "         k+=1\n",
    "    results_dir = results_dir+str(k)\n",
    "    try:\n",
    "        os.mkdir(results_dir)\n",
    "    except OSError as error:  \n",
    "            print(error)\n",
    "else:\n",
    "    try:\n",
    "        os.mkdir(results_dir)\n",
    "    except OSError as error:  \n",
    "            print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inputs, targets, model, optimizer, criterion):\n",
    "    device =torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    mae_loss = nn.L1Loss()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "    predictions = model(inputs)\n",
    "    loss = criterion(predictions.squeeze(), targets)\n",
    "    mae = mae_loss(predictions.squeeze(), targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    acc = 0\n",
    "    for i in range(len(predictions)):\n",
    "        pred = round(predictions[i].item())\n",
    "        target = int(targets[i].item())\n",
    "        if pred == target:\n",
    "            acc +=1\n",
    "    acc /= len(predictions)\n",
    "    del inputs, targets\n",
    "    torch.cuda.empty_cache()\n",
    "    return acc, loss.item(), mae.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_step(inputs, targets, model, criterion):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    mae_loss = nn.L1Loss()\n",
    "    model.eval()\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "    acc = 0\n",
    "    with torch.no_grad():\n",
    "        predictions = model(inputs)\n",
    "        loss = criterion(predictions.squeeze(), targets)\n",
    "        mae = mae_loss(predictions.squeeze(), targets)\n",
    "        for i in range(len(predictions)):\n",
    "            pred = round(predictions[i].item())\n",
    "            target = int(targets[i].item())\n",
    "            if pred == target:\n",
    "                acc +=1\n",
    "    acc /= len(predictions)\n",
    "    del inputs, targets\n",
    "    torch.cuda.empty_cache()\n",
    "    return acc, loss.item(), mae.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match loss_f:\n",
    "    case 'MSE':\n",
    "        criterion = nn.MSELoss()\n",
    "    case 'MAE':\n",
    "        criterion = nn.L1Loss()\n",
    "    case 'Huber':\n",
    "        criterion = nn.HuberLoss(delta = delta)\n",
    "        \n",
    "match optim:\n",
    "    case 'SGD':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    case 'Adadelta':\n",
    "        optimizer = torch.optim.Adadelta(model.parameters(), lr = 1., rho = 0.95, eps=1e-6)\n",
    "    case 'Adagrad':\n",
    "        optimizer = torch.optim.Adagrad(model.parameters())\n",
    "    case 'RMSprop':\n",
    "        optimizer = torch.optim.RMSprop(model.parameters())\n",
    "    case 'Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), betas=[0.9, 0.8])\n",
    "    case 'Rprop':\n",
    "        optimizer = torch.optim.Rprop(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_training_losses = []\n",
    "average_training_accs = []\n",
    "average_val_accs = []\n",
    "average_val_losses = []\n",
    "average_training_maes = []\n",
    "average_val_maes = []\n",
    "best_val_accs = 0\n",
    "best_epoch = 0\n",
    "\n",
    "start_time = time.time()\n",
    "# utiliser le GPU si disponible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "with open(os.path.join(results_dir, 'record.tsv'), 'w') as tsvfile:\n",
    "    writer = csv.writer(tsvfile, delimiter = '\\t', lineterminator = '\\n')\n",
    "    writer.writerow(['epoch', 'train_loss', 'train_acc', 'val_loss', 'val_acc'])\n",
    "    for epoch in range(num_epochs):\n",
    "        training_losses = []\n",
    "        training_accs = []\n",
    "        training_maes = []\n",
    "        desc = 'Epoch ' + str(epoch) + '/' + str(num_epochs)\n",
    "        for (x_train, y_train) in tqdm(dataloaders['train'], desc = desc):\n",
    "            acc, loss, mae = train_step(x_train, y_train, model, optimizer, criterion)\n",
    "            training_losses.append(loss)\n",
    "            training_accs.append(acc)\n",
    "            training_maes.append(mae)\n",
    "        average_training_loss = sum(training_losses) / len(training_losses)\n",
    "        average_training_acc = sum(training_accs) / len(training_accs)\n",
    "        average_training_mae = sum(training_maes) / len(training_maes)\n",
    "        average_training_losses.append(average_training_loss)\n",
    "        average_training_accs.append(average_training_acc)\n",
    "        average_training_maes.append(average_training_mae)\n",
    "\n",
    "        # Evaluation\n",
    "        val_accs = []\n",
    "        val_loss = []\n",
    "        val_maes = []\n",
    "        for x_val, y_val in dataloaders['val']:\n",
    "            acc, loss, mae = val_step(x_val, y_val, model, criterion)\n",
    "            val_accs.append(acc)\n",
    "            val_loss.append(loss)\n",
    "            val_maes.append(mae)\n",
    "        average_val_loss = sum(val_loss) / len(val_loss)\n",
    "        average_val_acc = sum(val_accs) / len(val_accs)\n",
    "        average_val_mae = sum(val_maes)/len(val_maes)\n",
    "        average_val_accs.append(average_val_acc)\n",
    "        average_val_losses.append(average_val_loss)\n",
    "        average_val_maes.append(average_val_mae)\n",
    "        if best_val_accs < average_val_acc:\n",
    "            torch.save(model.state_dict(), os.path.join(results_dir, 'best.pt'))\n",
    "            best_val_accs = average_val_acc\n",
    "            best_epoch = epoch\n",
    "            print(\"New best model: \", best_val_accs)\n",
    "        writer.writerow([epoch, average_training_loss, average_training_acc, average_val_loss, average_val_acc])\n",
    "        print(f'Training Loss: {average_training_loss}, Validation Acc: {average_val_acc}, Validation Loss: {average_val_loss}')\n",
    "\n",
    "end_t = time.time()\n",
    "time_elapsed=end_t - start_time\n",
    "legend = ['train', 'val']\n",
    "print(\"time_elapsed: {}\".format(time_elapsed))\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "fig = plt.figure(layout=\"constrained\", figsize=(20,10))\n",
    "gs = GridSpec(3, 1, figure=fig, wspace = 0.1)\n",
    "fig.suptitle('Results', fontsize=16)\n",
    "\n",
    "ax = fig.add_subplot(gs[0])\n",
    "intervals = np.arange(len(average_training_losses))\n",
    "ax.plot(intervals, average_training_losses, color = 'b')\n",
    "intervals = np.arange(1,len(average_training_losses))\n",
    "ax.plot(intervals, average_val_losses[1:], color = 'g')\n",
    "ax.set_ylabel(\"loss: \" + criterion._get_name())\n",
    "\n",
    "ax = fig.add_subplot(gs[1])\n",
    "intervals = np.arange(len(average_training_accs))\n",
    "ax.plot(intervals, average_training_maes, color = 'b')\n",
    "intervals = np.arange(1,len(average_training_accs))\n",
    "ax.plot(intervals, average_val_maes[1:], color = 'g')\n",
    "ax.set_ylabel(\"loss: MAE\")\n",
    "\n",
    "ax = fig.add_subplot(gs[2])\n",
    "intervals = np.arange(len(average_training_accs))\n",
    "ax.plot(intervals, average_training_accs, color = 'b')\n",
    "ax.plot(intervals, average_val_accs, color = 'g')\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "\n",
    "fig.legend(legend)\n",
    "fig.savefig(os.path.join(results_dir, 'results.png'))\n",
    "print(\"Evaluation accuracy (best) = \", best_val_accs)\n",
    "# clear GPU cache memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "yaml_dict = {'best epoch': best_epoch,\n",
    "             'best val acc': best_val_accs,\n",
    "             'train loss': average_training_losses[best_epoch],\n",
    "             'train acc': average_training_accs[best_epoch],\n",
    "             'train mae loss': average_training_maes[best_epoch],\n",
    "             'val loss': average_val_accs[best_epoch],\n",
    "             'val mae loss': average_val_maes[best_epoch],\n",
    "             'time': str(datetime.timedelta(seconds=time_elapsed))}\n",
    "with open(os.path.join(results_dir, 'results.yaml'), 'w') as yamlf:\n",
    "    yaml.dump(yaml_dict, yamlf, default_flow_style=False, allow_unicode=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yaml_dict = {'imgsz': [padded_w, padded_h],\n",
    "             'batch size': batch_size, \n",
    "             'epochs': num_epochs, \n",
    "             'loss function': loss_f,\n",
    "             'delta': delta,\n",
    "             'optim': optim, \n",
    "             'lr' : lr}\n",
    "with open(os.path.join(results_dir, 'args.yaml'), 'w') as yamlf:\n",
    "    yaml.dump(yaml_dict, yamlf, default_flow_style=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats = summary(model, input_size=(batch_size, 3, 224, 224), row_settings=(\"depth\", \"ascii_only\"))\n",
    "summary_str = str(model_stats)\n",
    "with open(os.path.join(results_dir, 'model.txt'), 'w') as modelf:\n",
    "    modelf.write(summary_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.load_state_dict(torch.load(os.path.join('best.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('dataset', 'val')\n",
    "plt.style.use('default')\n",
    "def parse_json_dict(path):\n",
    "    fname = glob('*.json', dir_fd=path)[0]\n",
    "    with open(os.path.join(path, fname)) as json_f:\n",
    "        labels = json.load(json_f)\n",
    "    return labels\n",
    "labels = parse_json_dict(path)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "fnames= glob('*.jpg', dir_fd = path)\n",
    "fnames = random.sample(fnames, 1)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "for fname in fnames:\n",
    "    image = Image.open(os.path.join(path, fname)).convert(\"RGB\")\n",
    "    print(np.asarray(image).shape)\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    image = data_transforms(image)\n",
    "    image = torch.unsqueeze(image, dim=0)\n",
    "    image = image.to(device)\n",
    "    pred = model(image)\n",
    "    print('predicted: ', pred[0][0].item())\n",
    "    print('predicted round: ', round(pred[0][0].item()))\n",
    "    print('truth: ', labels[fname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(model, path, transform):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    fnames= glob('*.jpg', dir_fd = path)\n",
    "    labels = parse_json_dict(path)\n",
    "    # init matrix\n",
    "    indices_t = np.linspace(1, max(labels.values()), max(labels.values()))\n",
    "    indices_p = np.linspace(1, 40, 40)\n",
    "    confusion_matrix = np.zeros((indices_p.size+1, indices_t.size), dtype = np.int16)\n",
    "    # predictions\n",
    "    model.eval()\n",
    "    for fname in fnames:\n",
    "        image = Image.open(os.path.join(path, fname)).convert(\"RGB\")\n",
    "        image = transform(image)\n",
    "        image = torch.unsqueeze(image, dim=0)\n",
    "        image = image.to(device)\n",
    "        pred = model(image)\n",
    "        pred = round(pred[0][0].item())\n",
    "        if pred in indices_p:\n",
    "            confusion_matrix[pred-1][labels[fname]-1]+=1\n",
    "        else:\n",
    "            confusion_matrix[-1][labels[fname]-1]+=1\n",
    "    return confusion_matrix, indices_p, indices_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('dataset', 'val')\n",
    "conf_mat, inds_p, inds_t = get_confusion_matrix(model, path, data_transforms)\n",
    "inds_p = np.append(inds_p, 'other')\n",
    "df_cm = pd.DataFrame(conf_mat, index = [i for i in inds_p],\n",
    "                  columns = [i for i in inds_t])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.ylabel('predicted')\n",
    "plt.xlabel('ground truth')\n",
    "plt.title('Val confusion matrix')\n",
    "#plt.savefig(os.path.join(results_dir, 'val_conf_mat.png'))\n",
    "\n",
    "# train\n",
    "path = os.path.join('dataset', 'train')\n",
    "conf_mat, inds_p, inds_t = get_confusion_matrix(model, path, data_transforms)\n",
    "inds_p = np.append(inds_p, 'other')\n",
    "df_cm = pd.DataFrame(conf_mat, index = [i for i in inds_p],\n",
    "                  columns = [i for i in inds_t])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.ylabel('predicted')\n",
    "plt.xlabel('ground truth')\n",
    "plt.title('train confusion matrix')\n",
    "#plt.savefig(os.path.join(results_dir, 'train_conf_mat.png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
