{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa: E501\n",
    "\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import supervision as sv\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from enum import Enum, auto\n",
    "import rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoxType(Enum):\n",
    "    B4 = \"B4\"\n",
    "    B8 = \"B8\"\n",
    "    G4 = \"4G\"\n",
    "    G8 = \"8G\"\n",
    "    G3 = \"3G\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_coords_1 = [(298, 475), (1498, 475), (1498, 864), (298, 864)]\n",
    "\n",
    "# Zone 1 needs to be done again from raw input (scale issue)\n",
    "zones_front_row_1 = {\n",
    "    0: [(15, 199), (21, 109), (106, 3), (156, 48), (78, 183), (64, 231), (12, 226)],\n",
    "    1: [(67, 232), (79, 185), (155, 49), (172, 63), (115, 179), (96, 231)],\n",
    "    2: [(101, 232), (124, 159), (173, 64), (181, 77), (161, 117), (159, 231)],\n",
    "    3: [(191, 63), (161, 115), (160, 232), (218, 233), (207, 118), (236, 50), (202, 45)],\n",
    "    4: [(224, 233), (210, 123), (254, 11), (285, 12), (272, 79), (281, 152), (270, 230)],\n",
    "    5: [(288, 12), (323, 13), (316, 82), (330, 232), (271, 232), (284, 151), (275, 85)],\n",
    "    6: [(337, 229), (326, 112), (329, 1), (374, 4), (386, 55), (385, 80), (399, 230)],\n",
    "    7: [(382, 3), (401, 127), (404, 233), (463, 231), (458, 96), (426, 1)],\n",
    "}\n",
    "\n",
    "zones_top_1_rigth = {\n",
    "    0: [(1497, 911), (884, 935), (441, 889), (7, 844), (7, 918), (613, 980), (1106, 1003), (1487, 979)],\n",
    "    1: [(1521, 792), (549, 794), (3, 739), (2, 838), (733, 891), (1499, 896)],\n",
    "    2: [(1536, 658), (472, 552), (2, 515), (4, 649), (731, 708), (1525, 765)],\n",
    "    3: [(1546, 547), (532, 448), (2, 402), (1, 511), (794, 574), (1538, 652)],\n",
    "    4: [(1594, 423), (976, 366), (155, 309), (2, 294), (3, 400), (727, 457), (1605, 536)],\n",
    "    5: [(1523, 279), (373, 192), (2, 179), (3, 294), (696, 343), (1517, 395)],\n",
    "    6: [(1534, 124), (1290, 89), (924, 66), (436, 46), (2, 50), (3, 169), (858, 186), (1531, 240)],\n",
    "    7: [(1552, 115), (1245, 79), (801, 36), (3, 43), (3, 3), (1560, 3)],\n",
    "}\n",
    "\n",
    "\n",
    "zones_front_row_2 = {\n",
    "    0: [(60, 306), (27, 165), (115, 5), (206, 13), (125, 176), (140, 315)],\n",
    "    1: [(166, 333), (163, 129), (240, 1), (341, 13), (293, 146), (327, 354)],\n",
    "    2: [(330, 351), (305, 143), (344, 3), (482, 4), (417, 135), (421, 357)],\n",
    "    3: [(437, 358), (434, 138), (491, 1), (576, 4), (528, 140), (525, 359)],\n",
    "    4: [(542, 356), (537, 145), (583, 6), (657, 8), (634, 148), (622, 357)],\n",
    "    5: [(652, 351), (659, 10), (758, 13), (796, 347)],\n",
    "    6: [(801, 347), (770, 93), (921, 97), (965, 187), (939, 355)],\n",
    "    7: [(941, 353), (968, 191), (925, 97), (974, 88), (1040, 246), (1041, 358)],\n",
    "    8: [(1043, 359), (1042, 249), (976, 93), (955, 27), (992, 1), (1134, 3), (1198, 189), (1193, 361)],\n",
    "}\n",
    "\n",
    "\n",
    "zones_top_2_rigth = {\n",
    "    0: [(24, 971), (1624, 948), (1630, 1079), (24, 1079)],\n",
    "    1: [(1621, 825), (22, 838), (21, 938), (1078, 944), (1633, 919)],\n",
    "    2: [(1604, 712), (27, 712), (25, 834), (835, 856), (1621, 816)],\n",
    "    3: [(1571, 577), (22, 548), (26, 671), (1578, 690)],\n",
    "    4: [(1568, 460), (24, 439), (21, 545), (1571, 573)],\n",
    "    5: [(1566, 319), (24, 326), (22, 437), (1566, 457)],\n",
    "    6: [(1544, 204), (26, 213), (24, 323), (1563, 317)],\n",
    "    7: [(1474, 96), (26, 77), (26, 203), (1485, 197)],\n",
    "    8: [(1472, 90), (27, 70), (33, 0), (1484, 0)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_zones(image_path, loaded_zones):\n",
    "    zones = loaded_zones.copy()  # Dictionary to store polygons: dict[int, list[tuple[int, int]]]\n",
    "    current_zone = []  # Temporary list to store points of current polygon\n",
    "    current_zone_id = max(zones.keys()) + 1 if zones else 0  # ID of current polygon, start after highest existing ID\n",
    "    drawing = False  # Flag to track if we're currently drawing\n",
    "    img_copy = None  # Copy of original image for drawing\n",
    "\n",
    "    def mouse_callback(event, x, y, flags, param):\n",
    "        nonlocal drawing, current_zone, img_copy\n",
    "\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:  # Start drawing\n",
    "            if not drawing:\n",
    "                drawing = True\n",
    "                current_zone = [(x, y)]\n",
    "                img_copy = frame.copy()\n",
    "            else:  # Add point to current polygon\n",
    "                current_zone.append((x, y))\n",
    "\n",
    "            # Draw points and lines\n",
    "            if len(current_zone) > 0:\n",
    "                # Draw all points\n",
    "                for point in current_zone:\n",
    "                    cv2.circle(img_copy, point, 3, (0, 255, 0), -1)\n",
    "                # Draw lines between points\n",
    "                if len(current_zone) > 1:\n",
    "                    for i in range(len(current_zone) - 1):\n",
    "                        cv2.line(img_copy, current_zone[i], current_zone[i + 1], (255, 0, 0), 2)\n",
    "\n",
    "        elif event == cv2.EVENT_MOUSEMOVE and drawing:\n",
    "            # Create temporary image for preview\n",
    "            temp_img = img_copy.copy()\n",
    "            if len(current_zone) > 0:\n",
    "                # Draw line from last point to current mouse position\n",
    "                cv2.line(temp_img, current_zone[-1], (x, y), (255, 0, 0), 2)\n",
    "            cv2.imshow(\"Zone Creation\", temp_img)\n",
    "\n",
    "    # Read the image\n",
    "    # frame = preporcess_front_image(image_path, cut_coords_1, rgb=False)\n",
    "    frame = cv2.imread(image_path)\n",
    "    img_copy = frame.copy()\n",
    "\n",
    "    # Draw existing zones\n",
    "    for _, points in zones.items():\n",
    "        cv2.polylines(frame, [np.array(points)], True, (0, 255, 0), 2)\n",
    "    img_copy = frame.copy()\n",
    "\n",
    "    cv2.namedWindow(\"Zone Creation\")\n",
    "    cv2.setMouseCallback(\"Zone Creation\", mouse_callback)\n",
    "\n",
    "    print(\"Instructions:\")\n",
    "    print(\"- Left click to add points\")\n",
    "    print(\"- Press 'Enter' to complete current zone\")\n",
    "    print(\"- Press 'q' to finish and save all zones\")\n",
    "    print(\"- Press 'r' to reset current zone\")\n",
    "\n",
    "    while True:\n",
    "        cv2.imshow(\"Zone Creation\", img_copy)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == ord(\"q\"):  # Quit\n",
    "            break\n",
    "        elif key == 13:  # Enter key - complete current polygon\n",
    "            if len(current_zone) >= 3:  # Only save if we have at least 3 points\n",
    "                zones[current_zone_id] = current_zone\n",
    "                current_zone_id += 1\n",
    "                drawing = False\n",
    "                current_zone = []\n",
    "                # Draw the completed polygon permanently\n",
    "                cv2.polylines(frame, [np.array(zones[current_zone_id - 1])], True, (0, 255, 0), 2)\n",
    "                img_copy = frame.copy()\n",
    "        elif key == ord(\"r\"):  # Reset current zone\n",
    "            current_zone = []\n",
    "            img_copy = frame.copy()\n",
    "            drawing = False\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    return zones\n",
    "\n",
    "\n",
    "# Use the function\n",
    "zones = create_zones(\n",
    "    \"../data/new/test/2/row2_top_right_2025-01-15_16-23-59_corrected.jpg\",\n",
    "    loaded_zones={}\n",
    ")\n",
    "print(\"\\nCreated zones:\")\n",
    "print(zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@14.309] global loadsave.cpp:241 findDecoder imread_('../data\\new\\test\\2\\row2_front__2025-01-15_16-23-59.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not read image at ../data\\new\\test\\2\\row2_front__2025-01-15_16-23-59.jpg",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 31\u001b[0m\n\u001b[1;32m     27\u001b[0m         plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cropped\n\u001b[0;32m---> 31\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_front_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mnew\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m2\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mrow2_front__2025-01-15_16-23-59.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcut_coords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcut_coords_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m, in \u001b[0;36mpreprocess_front_image\u001b[0;34m(path, cut_coords, show, rgb)\u001b[0m\n\u001b[1;32m      6\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;28mstr\u001b[39m(path))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not read image at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m cut_coords \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(cut_coords)\n\u001b[1;32m     11\u001b[0m x_min \u001b[38;5;241m=\u001b[39m cut_coords[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()\n",
      "\u001b[0;31mValueError\u001b[0m: Could not read image at ../data\\new\\test\\2\\row2_front__2025-01-15_16-23-59.jpg"
     ]
    }
   ],
   "source": [
    "def preprocess_front_image(path: Path, cut_coords: list[tuple[int, int]], show: bool = False, rgb: bool = True) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Take the path to the raw camera output, returns the zoomed in image.\n",
    "    Cut coords depends on the camera id.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(str(path))\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not read image at {path}\")\n",
    "        \n",
    "    cut_coords = np.array(cut_coords)\n",
    "    x_min = cut_coords[:, 0].min()\n",
    "    x_max = cut_coords[:, 0].max() \n",
    "    y_min = cut_coords[:, 1].min()\n",
    "    y_max = cut_coords[:, 1].max()\n",
    "\n",
    "    # Crop the image\n",
    "    cropped = img[y_min:y_max, x_min:x_max]\n",
    "    \n",
    "    # Convert to RGB if requested\n",
    "    if rgb:\n",
    "        cropped = cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Show the cropped image if requested\n",
    "    if show:\n",
    "        plt.figure(figsize=(12,8))\n",
    "        plt.imshow(cropped if rgb else cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        \n",
    "    return cropped\n",
    "\n",
    "res = preprocess_front_image(\n",
    "    r\"../data\\new\\test\\2\\row2_front__2025-01-15_16-23-59.jpg\",\n",
    "    cut_coords=cut_coords_1,\n",
    "    show=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_each_row(\n",
    "    front_img_path: Path, zones: dict[int, list[tuple[int, int]]], debug=False, min_conf=0.5\n",
    ") -> dict[int, BoxType]:\n",
    "    \"\"\"\n",
    "    Return a dictionary where keys are row number and values are box types\n",
    "    \"\"\"\n",
    "    frame = preprocess_front_image(front_img_path, cut_coords=[(298, 475), (1498, 475), (1498, 864), (298, 864)],rgb=False)\n",
    "    \n",
    "    model = YOLO(\"guide_results/frontview_detection/weights/best.pt\")\n",
    "    results = model(frame, conf=min_conf)[0]\n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "    # detections = detections[detections.confidence > min_conf]\n",
    "\n",
    "    row_types: dict[int, BoxType] = {}\n",
    "\n",
    "    for box, class_id, conf in zip(detections.xyxy, detections.class_id, detections.confidence):\n",
    "        center_x = (box[0] + box[2]) / 2\n",
    "        center_y = (box[1] + box[3]) / 2\n",
    "        center_point = (int(center_x), int(center_y))\n",
    "\n",
    "        # Check which zone contains this point\n",
    "        for zone_id, zone_points in zones.items():\n",
    "            if cv2.pointPolygonTest(np.array(zone_points), center_point, False) >= 0:\n",
    "                if zone_id in row_types:\n",
    "                    print(f\"Warning: Multiple detections in zone {zone_id}\")\n",
    "                row_types[zone_id] = BoxType(model.names[class_id])\n",
    "                break\n",
    "\n",
    "    for i in range(len(zones)):\n",
    "        if i not in row_types:\n",
    "            row_types[i] = None\n",
    "\n",
    "    if debug:\n",
    "        box_annotator = sv.BoxAnnotator(thickness=1)\n",
    "        label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "        labels = [\n",
    "            f\"{model.names[class_id]} {confidence:0.2f}\"\n",
    "            for confidence, class_id in zip(detections.confidence, detections.class_id)\n",
    "        ]\n",
    "\n",
    "        # Draw zones\n",
    "        annotated_frame = frame.copy()\n",
    "        for zone_id, points in zones.items():\n",
    "            # Draw zone polygon\n",
    "            cv2.polylines(annotated_frame, [np.array(points)], True, (255, 0, 0), 1)\n",
    "\n",
    "            # Calculate centroid for zone label\n",
    "            centroid = np.mean(points, axis=0).astype(int)\n",
    "\n",
    "            # Get text size to center it\n",
    "            text = f\"Zone {zone_id+1}\"\n",
    "            (text_width, text_height), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "\n",
    "            # Adjust centroid coordinates to center the text\n",
    "            text_x = int(centroid[0] - text_width / 2)\n",
    "            text_y = int(centroid[1] + text_height / 2)\n",
    "\n",
    "            cv2.putText(annotated_frame, text, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "\n",
    "        # Annotate boxes\n",
    "        annotated_frame = box_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "        annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections, labels=labels)\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(annotated_frame)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    return row_types\n",
    "\n",
    "\n",
    "# Example usage\n",
    "result = identify_each_row(\n",
    "    \"../data/new/test/2/row2_front__2025-01-15_16-23-59.jpg\", zones_front_row_2, debug=True, min_conf=0.2\n",
    ")\n",
    "for i in range(len(result)):\n",
    "    print(f\"Zone {i+1}: {result[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_path = r\"C:\\Users\\Dorian\\Desktop\\sewww\\fisheyegl\"\n",
    "\n",
    "\n",
    "def correct_fisheye(path):\n",
    "    base_path = Path(path).parent\n",
    "    name = Path(path).stem\n",
    "    corrected_path = base_path / f\"{name}_corrected.jpg\"\n",
    "    \n",
    "    if not corrected_path.exists():\n",
    "        os.system(f\"bun {script_path}/script.js {path} {corrected_path} --Fy=0.27\")\n",
    "\n",
    "\n",
    "correct_fisheye(r\"D:\\Programmation\\TPS\\sew\\data\\new\\test\\2\\row2_top_right_2025-01-15_16-23-59.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_boxes_per_row(\n",
    "    img_top_path: Path, zones: dict[int, list[tuple[int, int]]], min_conf=0.6, debug=False\n",
    ") -> dict[int, int]:\n",
    "    \"\"\"\n",
    "    Returns a dict containing the number of boxes in each row, where keys are row numbers and values are the number of boxes\n",
    "    \"\"\"\n",
    "\n",
    "    correct_fisheye(img_top_path)\n",
    "\n",
    "    # Inference for top view\n",
    "    model = YOLO(\"guide_results/top_detection4/weights/best.pt\")\n",
    "    corrected_path = str(img_top_path).replace(\".jpg\", \"_corrected.jpg\")\n",
    "    frame = cv2.imread(corrected_path)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Get original dimensions\n",
    "    orig_h, orig_w = frame.shape[:2]\n",
    "\n",
    "    # Resize frame\n",
    "    new_h, new_w = 1000, 1000\n",
    "    frame = cv2.resize(frame, (new_w, new_h))\n",
    "\n",
    "    # Calculate scale factors\n",
    "    scale_x = new_w / orig_w\n",
    "    scale_y = new_h / orig_h\n",
    "\n",
    "    # Scale zones\n",
    "    scaled_zones = {}\n",
    "    for zone_id, points in zones.items():\n",
    "        scaled_points = [(int(x * scale_x), int(y * scale_y)) for x, y in points]\n",
    "        scaled_zones[zone_id] = scaled_points\n",
    "\n",
    "    zones = scaled_zones\n",
    "\n",
    "    results = model(frame, conf=min_conf)[0]\n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "    # Initialize counts for all zones\n",
    "    boxes_per_row = {i: 0 for i in zones.keys()}\n",
    "\n",
    "    # For each detection, check which zone it belongs to\n",
    "    for box, class_id, conf in zip(detections.xyxy, detections.class_id, detections.confidence):\n",
    "        center_x = (box[0] + box[2]) / 2\n",
    "        center_y = (box[1] + box[3]) / 2\n",
    "        center_point = (center_x, center_y)\n",
    "\n",
    "        # Check which zone contains this point\n",
    "        for zone_id, zone_points in zones.items():\n",
    "            zone_polygon = np.array(zone_points)\n",
    "            if cv2.pointPolygonTest(zone_polygon, center_point, False) >= 0:\n",
    "                boxes_per_row[zone_id] += 1\n",
    "                break\n",
    "\n",
    "    if debug:\n",
    "        box_annotator = sv.BoxAnnotator()\n",
    "        annotated_frame = box_annotator.annotate(scene=frame.copy(), detections=detections)\n",
    "\n",
    "        # Draw zones\n",
    "        for zone_id, points in zones.items():\n",
    "            # Draw zone polygon\n",
    "            cv2.polylines(annotated_frame, [np.array(points)], True, (255, 0, 0), 1)\n",
    "\n",
    "            # Calculate centroid for zone label\n",
    "            centroid = np.mean(points, axis=0).astype(int)\n",
    "            text = f\"Zone {zone_id+1}: {boxes_per_row[zone_id]}\"\n",
    "\n",
    "            # Get text size to center it\n",
    "            (text_width, text_height), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "\n",
    "            # Adjust centroid coordinates to center the text\n",
    "            text_x = int(centroid[0] - text_width / 2)\n",
    "            text_y = int(centroid[1] + text_height / 2)\n",
    "\n",
    "            cv2.putText(annotated_frame, text, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 1)\n",
    "\n",
    "        # Draw center points of boxes\n",
    "        for box in detections.xyxy:\n",
    "            center_x = int((box[0] + box[2]) / 2)\n",
    "            center_y = int((box[1] + box[3]) / 2)\n",
    "            cv2.circle(annotated_frame, (center_x, center_y), 3, (255, 0, 0), -1)  # Draw filled circle\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(annotated_frame)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    return boxes_per_row\n",
    "\n",
    "\n",
    "res = count_boxes_per_row(\n",
    "    \"../data/new/test/2/row2_top_right_2025-01-15_16-23-59.jpg\", zones=zones_top_2_rigth, debug=True, min_conf=0.1\n",
    ")\n",
    "for i, count in res.items():\n",
    "    print(f\"Row {i}: {count} boxes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def count_boxes(front_img_path: Path, top_img_path: Path) -> dict[BoxType, int]:\n",
    "    \"\"\"\n",
    "    Return a dict object containing a count for each box type. The keys are the box types and the values are the counts.\n",
    "    \"\"\"\n",
    "    row_types = identify_each_row(front_img_path, zones_front_row_2, debug=True, min_conf=0.5)\n",
    "    boxes_per_row = count_boxes_per_row(top_img_path, zones_top_2_rigth, debug=True, min_conf=0.5)\n",
    "\n",
    "    pprint(row_types)\n",
    "    pprint(boxes_per_row)\n",
    "\n",
    "    # Initialize counts for each box type\n",
    "    box_counts = {box_type: 0 for box_type in BoxType}\n",
    "\n",
    "    # Count boxes of each type\n",
    "    for row, box_type in row_types.items():\n",
    "        if box_type is not None:\n",
    "            box_counts[box_type] += boxes_per_row[row]\n",
    "\n",
    "    return box_counts\n",
    "\n",
    "\n",
    "res = count_boxes(\"../data/new/test/2/row2_front__2025-01-15_16-23-59.jpg\", \"../data/new/test/2/row2_top_right_2025-01-15_16-23-59.jpg\")\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
