{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO models from ultralytics\n",
    "\n",
    "This notebook allows you to train and test YOLO models from ultralytics.\n",
    "\n",
    "Here is a list of available models : https://hub.ultralytics.com/models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (8.2.8)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from ultralytics) (3.8.4)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from ultralytics) (4.9.0.80)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from ultralytics) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from ultralytics) (1.12.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from ultralytics) (2.2.2+cu121)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from ultralytics) (0.17.2+cu121)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from ultralytics) (4.66.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from ultralytics) (5.9.8)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Collecting thop>=0.1.1 (from ultralytics)\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from ultralytics) (2.2.1)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from ultralytics) (0.12.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (6.1.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2023.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: thop\n",
      "Successfully installed thop-0.1.1.post2209072238\n",
      "Collecting roboflow\n",
      "  Downloading roboflow-1.1.28-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting certifi==2023.7.22 (from roboflow)\n",
      "  Downloading certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting chardet==4.0.0 (from roboflow)\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting cycler==0.10.0 (from roboflow)\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl.metadata (722 bytes)\n",
      "Collecting idna==2.10 (from roboflow)\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from roboflow) (1.4.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from roboflow) (3.8.4)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from roboflow) (1.26.4)\n",
      "Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n",
      "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from roboflow) (10.2.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from roboflow) (2.9.0)\n",
      "Collecting python-dotenv (from roboflow)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from roboflow) (2.31.0)\n",
      "Requirement already satisfied: six in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from roboflow) (2.1.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from roboflow) (4.66.2)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from roboflow) (6.0.1)\n",
      "Collecting requests-toolbelt (from roboflow)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting python-magic (from roboflow)\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from matplotlib->roboflow) (1.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from matplotlib->roboflow) (4.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from matplotlib->roboflow) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from matplotlib->roboflow) (3.0.9)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from matplotlib->roboflow) (6.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests->roboflow) (2.0.4)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->roboflow) (3.17.0)\n",
      "Downloading roboflow-1.1.28-py3-none-any.whl (74 kB)\n",
      "   ---------------------------------------- 0.0/74.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 74.6/74.6 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "   ---------------------------------------- 0.0/158.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 158.3/158.3 kB 4.8 MB/s eta 0:00:00\n",
      "Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "   ---------------------------------------- 0.0/178.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 178.7/178.7 kB ? eta 0:00:00\n",
      "Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.8/58.8 kB ? eta 0:00:00\n",
      "Downloading opencv_python_headless-4.8.0.74-cp37-abi3-win_amd64.whl (38.0 MB)\n",
      "   ---------------------------------------- 0.0/38.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/38.0 MB 11.1 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 2.2/38.0 MB 22.9 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 3.3/38.0 MB 30.0 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 6.0/38.0 MB 31.8 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 7.7/38.0 MB 32.7 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 9.7/38.0 MB 34.3 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 12.2/38.0 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 15.1/38.0 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 17.8/38.0 MB 54.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 21.0/38.0 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 23.9/38.0 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 26.2/38.0 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 29.3/38.0 MB 59.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 31.3/38.0 MB 59.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 33.8/38.0 MB 54.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 36.9/38.0 MB 54.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  37.9/38.0 MB 54.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.0/38.0 MB 40.9 MB/s eta 0:00:00\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "   ---------------------------------------- 0.0/54.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 54.5/54.5 kB ? eta 0:00:00\n",
      "Installing collected packages: python-magic, python-dotenv, opencv-python-headless, idna, cycler, chardet, certifi, requests-toolbelt, roboflow\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.7\n",
      "    Uninstalling idna-3.7:\n",
      "      Successfully uninstalled idna-3.7\n",
      "  Attempting uninstall: cycler\n",
      "    Found existing installation: cycler 0.11.0\n",
      "    Uninstalling cycler-0.11.0:\n",
      "      Successfully uninstalled cycler-0.11.0\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2024.2.2\n",
      "    Uninstalling certifi-2024.2.2:\n",
      "      Successfully uninstalled certifi-2024.2.2\n",
      "Successfully installed certifi-2023.7.22 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 python-dotenv-1.0.1 python-magic-0.4.27 requests-toolbelt-1.0.0 roboflow-1.1.28\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n",
    "!pip install roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.134 is required but found version=8.2.14, to fix: `pip install ultralytics==8.0.134`\n",
      "Downloading Dataset Version Zip in counting-rolls-2 to yolov8: 100% [7364076 / 7364076] bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to counting-rolls-2 in yolov8:: 100%|██████████| 194/194 [00:00<00:00, 12435.16it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"Z4mFtu232oWID8Vtcntw\")\n",
    "project = rf.workspace(\"testsew\").project(\"counting-rolls\")\n",
    "version = project.version(2)\n",
    "dataset = version.download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicol\\Documents\\GitHub\\sew\\YOLO_ROLLS\\counting-rolls-1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = os.path.join(os.getcwd(), \"counting-rolls-1\")\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose what version of yolo you want.\n",
    "| Model | size<br><sup>(pixels) | mAP<sup>val<br>50-95 | Speed<br><sup>CPU ONNX<br>(ms) | Speed<br><sup>A100 TensorRT<br>(ms) | params<br><sup>(M) | FLOPs<br><sup>(B) |\n",
    "| ----------------------------------------------------------------------------------------- | --------------------- | -------------------- | ------------------------------ | ----------------------------------- | ------------------ | ----------------- |\n",
    "| [YOLOv8n](https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n-oiv7.pt) | 640 | 18.4 | 142.4 | 1.21 | 3.5 | 10.5 |\n",
    "| [YOLOv8s](https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8s-oiv7.pt) | 640 | 27.7 | 183.1 | 1.40 | 11.4 | 29.7 |\n",
    "| [YOLOv8m](https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8m-oiv7.pt) | 640 | 33.6 | 408.5 | 2.26 | 26.2 | 80.6 |\n",
    "| [YOLOv8l](https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8l-oiv7.pt) | 640 | 34.9 | 596.9 | 2.43 | 44.1 | 167.4 |\n",
    "| [YOLOv8x](https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8x-oiv7.pt) | 640 | 36.3 | 860.6 | 3.56 | 68.7 | 260.6 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l.pt to 'yolov8l.pt'...\n",
      "100%|██████████████████████████████████████| 83.7M/83.7M [00:01<00:00, 59.5MB/s]\n",
      "Ultralytics YOLOv8.2.14 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 4090, 24195MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8l.pt, data=/home/nicolastovantrang/Desktop/sew/YOLO_ROLLS/counting-rolls-1/data.yaml, epochs=150, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 22        [15, 18, 21]  1   5586655  ultralytics.nn.modules.head.Detect           [5, [256, 512, 512]]          \n",
      "Model summary: 365 layers, 43633695 parameters, 43633679 gradients, 165.4 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n",
      "100%|██████████████████████████████████████| 6.23M/6.23M [00:00<00:00, 37.4MB/s]\n",
      "/home/nicolastovantrang/Desktop/sew/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/nicolastovantrang/Desktop/sew/YOLO_ROLLS/counting-rolls-1/\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/nicolastovantrang/Desktop/sew/YOLO_ROLLS/counting-rolls-1/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/nicolastovantrang/Desktop/sew/YOLO_ROLLS/counting-rolls-1/va\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/nicolastovantrang/Desktop/sew/YOLO_ROLLS/counting-rolls-1/valid/labels.cache\n",
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 150 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]/home/nicolastovantrang/Desktop/sew/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "      1/150      10.1G      1.654      3.992      1.762         27        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.375      0.533      0.174      0.128\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      2/150      10.5G      1.363      2.364      1.516         48        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.382      0.875      0.494      0.369\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      3/150      10.5G      1.069      1.656      1.254         29        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.385      0.729      0.573      0.459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      4/150      10.7G      1.032      1.231      1.239         49        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12       0.18      0.933      0.253      0.227\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      5/150      10.7G     0.9804      1.132      1.184         29        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12       0.55      0.833      0.551      0.462\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      6/150      10.6G     0.9955      1.086      1.235         43        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.652      0.567      0.431      0.313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      7/150      10.7G      1.007      1.105      1.215         32        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.615      0.333       0.35      0.245\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      8/150      10.6G     0.9829       1.02      1.222         39        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.361      0.357      0.189      0.107\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      9/150      10.7G     0.9892     0.9137      1.164         34        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.708        0.1      0.108     0.0557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     10/150      10.5G      0.891     0.8938      1.142         28        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.208        0.1    0.00709    0.00161\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     11/150      10.5G     0.8784      0.874       1.12         37        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.383      0.467      0.163      0.059\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     12/150      10.5G     0.9655     0.8448      1.157         54        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.625        0.1     0.0278     0.0049\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     13/150      10.5G     0.9447     0.8322      1.166         44        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.393      0.271      0.154      0.126\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     14/150      10.5G     0.9463     0.8245      1.184         36        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.486      0.712      0.586      0.461\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     15/150      10.5G     0.8676     0.7919      1.107         29        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12       0.49      0.533      0.532      0.435\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     16/150      10.6G     0.9163     0.8649      1.106         29        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.279      0.752      0.417      0.363\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     17/150      10.8G     0.9688     0.9716      1.183         33        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.485      0.567      0.492      0.377\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     18/150      10.6G     0.8858     0.9213      1.119         37        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.686        0.6      0.771      0.463\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     19/150      10.5G      0.899      0.777      1.112         51        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.593      0.867      0.796      0.428\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     20/150      10.7G     0.8871     0.7585      1.115         53        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.705      0.606      0.743       0.43\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     21/150      10.5G     0.9498     0.7799      1.144         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.468      0.681      0.615      0.442\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     22/150      10.6G     0.9134     0.7961      1.137         49        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.581     0.0667      0.068     0.0408\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     23/150      10.5G     0.9029     0.7251      1.131         47        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.858      0.233      0.336      0.225\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     24/150      10.6G      0.862     0.7256      1.167         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.767      0.694      0.826      0.632\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     25/150      10.5G     0.8244     0.6821      1.126         29        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.865      0.575      0.737      0.614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     26/150      10.7G     0.8102     0.6634      1.082         35        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12       0.58        0.7      0.687      0.561\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     27/150      10.5G     0.7846     0.6402      1.073         44        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.548      0.767      0.695      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     28/150      10.6G     0.8321     0.6464        1.1         27        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.832        0.6      0.725      0.613\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     29/150      10.8G     0.7988     0.6385      1.093         30        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.881      0.588      0.655      0.552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     30/150      10.6G      0.799     0.6541      1.088         40        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.774      0.585      0.798      0.663\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     31/150      10.8G     0.7852     0.6537      1.086         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.706        0.7      0.776      0.698\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     32/150      10.6G     0.7209     0.6059      1.015         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.888      0.776      0.927      0.776\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     33/150      10.8G     0.8247     0.6155      1.079         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.716      0.742      0.868      0.723\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     34/150      10.7G     0.7266      0.644      1.034         37        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.853      0.791      0.887      0.797\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     35/150      10.5G     0.7542      0.655      1.071         33        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.764       0.52      0.581      0.497\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     36/150      10.6G     0.7475     0.6126      1.072         47        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.728      0.867      0.815      0.572\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     37/150      10.5G     0.6884     0.5767      1.022         36        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.745      0.933      0.798       0.71\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     38/150      10.6G     0.6784     0.5635      1.016         29        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12        0.9      0.652      0.678      0.582\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     39/150      10.5G     0.6985     0.5657      1.036         49        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.826      0.733      0.773      0.617\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     40/150      10.6G     0.6842     0.5104      1.056         26        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.848      0.909      0.898      0.511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     41/150      10.5G     0.6726     0.5519          1         55        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.878      0.843      0.923      0.707\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     42/150      10.6G     0.6683      0.515      1.007         31        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.886      0.933      0.896      0.779\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     43/150      10.8G     0.6841     0.5242      1.034         39        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.889      0.931      0.896      0.771\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     44/150      10.6G     0.6536     0.4966      1.037         26        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.866      0.772      0.843      0.735\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     45/150      10.5G      0.724     0.5446      1.055         30        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.771      0.767      0.824      0.723\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     46/150      10.6G     0.6467     0.4841      1.005         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.759      0.821       0.77      0.638\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     47/150      10.5G      0.661     0.5259      1.013         47        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12       0.74      0.796      0.824       0.67\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     48/150      10.6G     0.6949     0.5344      1.015         46        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12       0.79      0.673      0.897      0.759\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     49/150      10.5G     0.6789     0.5096      1.034         38        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.813      0.735      0.879      0.777\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     50/150      10.6G     0.6308     0.4748     0.9897         32        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.783      0.769      0.841      0.747\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     51/150      10.8G     0.6483     0.4667     0.9632         29        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.746      0.782      0.876      0.787\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     52/150      10.6G     0.6578     0.5285     0.9891         49        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.917      0.917      0.929      0.826\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     53/150      10.5G     0.6497     0.5278      0.991         34        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.941      0.868      0.995      0.876\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     54/150      10.6G     0.6748     0.5082      1.015         28        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.761      0.895      0.969      0.853\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     55/150      10.8G     0.6664     0.5271       1.01         32        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.827      0.896      0.969      0.872\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     56/150      10.6G     0.6135     0.4664     0.9892         37        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.809      0.918      0.879        0.8\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     57/150      10.8G     0.5523     0.4266     0.9449         42        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.859      0.784      0.867      0.779\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     58/150      10.7G      0.659     0.5069      1.035         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.814       0.72      0.786       0.71\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     59/150      10.5G     0.6376     0.4671      1.006         27        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12       0.82      0.715      0.788      0.739\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     60/150      10.6G     0.6477     0.4664      1.002         41        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.818      0.817      0.834      0.755\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     61/150      10.5G     0.6731     0.4814     0.9964         41        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.837      0.814      0.901      0.845\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     62/150      10.6G     0.5927     0.4481     0.9634         48        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.636      0.911      0.807       0.69\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     63/150      10.8G     0.6253     0.4679     0.9881         49        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.785       0.72      0.811      0.666\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     64/150      10.6G     0.5788     0.4473     0.9574         26        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.768      0.821      0.849      0.731\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     65/150      10.8G     0.5687      0.437     0.9562         37        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.874      0.767       0.73      0.682\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     66/150      10.6G     0.5502      0.441     0.9528         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12       0.79      0.927      0.899      0.785\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     67/150      10.5G     0.5986     0.4281     0.9688         47        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12        0.8      0.919      0.886      0.736\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     68/150      10.6G     0.6237     0.4496      0.977         40        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.687      0.933      0.821       0.71\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     69/150      10.8G     0.6126     0.4572     0.9685         39        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.737      0.878      0.854      0.781\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     70/150      10.6G     0.5662      0.427     0.9653         46        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.798      0.881      0.868      0.813\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     71/150      10.5G      0.544     0.4392     0.9625         54        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.776       0.91      0.867      0.793\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     72/150      10.7G     0.5211     0.3944     0.9483         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.824      0.843      0.798      0.676\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     73/150      10.5G     0.5124     0.3985     0.9319         33        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.782      0.843      0.831      0.756\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     74/150      10.6G     0.5088     0.3963     0.9415         61        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.776       0.86      0.924      0.798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     75/150      10.5G      0.533     0.4288     0.9922         32        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.905      0.833      0.874      0.772\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     76/150      10.6G     0.5228       0.42     0.9429         44        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.801      0.833       0.84      0.768\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     77/150      10.5G     0.5092     0.4211     0.9187         70        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.828      0.875      0.912      0.833\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     78/150      10.6G     0.5349     0.4191     0.9478         29        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.897      0.884      0.934       0.83\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     79/150      10.8G     0.5645     0.4357     0.9774         26        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.905      0.916      0.933      0.803\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     80/150      10.6G     0.5035     0.3756     0.9105         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.885      0.867      0.884      0.767\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     81/150      10.5G     0.5561     0.4368     0.9721         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.897      0.853      0.884      0.777\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     82/150      10.7G     0.5483     0.4288     0.9581         39        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.795      0.933      0.905      0.799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     83/150      10.5G      0.504     0.3852     0.9351         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.774      0.933      0.841      0.739\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     84/150      10.7G     0.5052      0.396     0.9313         49        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.792      0.933      0.874      0.791\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     85/150      10.5G     0.4927     0.3867     0.9159         36        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.819      0.918      0.879      0.776\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     86/150      10.6G     0.4902     0.3727     0.9222         46        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.842      0.777      0.852      0.749\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     87/150      10.8G     0.4953     0.3734     0.9407         48        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.881      0.778      0.816      0.723\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     88/150      10.6G     0.4872     0.3634     0.9094         47        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.869        0.8      0.879      0.798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     89/150      10.5G     0.4932     0.3611     0.9523         31        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.861      0.824      0.935      0.867\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     90/150      10.6G     0.4296     0.3231     0.8972         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.852      0.819      0.945      0.871\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     91/150      10.5G     0.4761     0.3618     0.9127         40        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.804      0.954      0.962      0.891\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     92/150      10.6G     0.4658     0.3672     0.9223         28        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.832      0.862      0.896      0.869\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     93/150      10.5G     0.4509     0.3565     0.9092         26        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.838      0.867      0.896      0.821\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     94/150      10.6G     0.4403     0.3609     0.8961         48        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.843      0.867      0.912       0.79\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     95/150      10.8G     0.4815     0.3586      0.929         37        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.897      0.869      0.946      0.808\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     96/150      10.6G     0.5037     0.3839     0.9542         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.904      0.933      0.946      0.866\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     97/150      10.8G     0.4614     0.3491     0.9279         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.911      0.919      0.912      0.798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     98/150      10.6G     0.4567     0.3535     0.9189         25        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.847      0.923      0.929      0.822\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     99/150      10.8G     0.4335     0.3516      0.894         30        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.878      0.832       0.89      0.791\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    100/150      10.7G     0.4431     0.3565     0.8994         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.831      0.867      0.889      0.778\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    101/150      10.8G     0.4128     0.3233     0.8929         41        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.827      0.865       0.89      0.789\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    102/150      10.6G     0.4283     0.3329     0.8924         41        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.815      0.861       0.86      0.771\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    103/150      10.8G     0.4517     0.3422     0.9185         45        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.811       0.86      0.863      0.778\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    104/150      10.6G     0.4481     0.3714     0.9193         26        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.814       0.86      0.924      0.839\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    105/150      10.8G        0.4     0.3233     0.8862         41        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.821      0.861      0.889      0.795\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    106/150      10.6G     0.4298     0.3417     0.9006         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.855      0.837      0.853      0.762\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    107/150      10.5G     0.5077     0.3823      1.002         27        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.891      0.853      0.888      0.801\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    108/150      10.6G     0.4177     0.3321     0.9069         41        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.864      0.917      0.942      0.851\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    109/150      10.8G     0.4084     0.3157     0.8811         48        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.858      0.921      0.942      0.858\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    110/150      10.6G     0.4212     0.3265     0.8935         47        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.794      0.933      0.942      0.875\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    111/150      10.5G     0.4308     0.3462     0.9028         43        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.786      0.925       0.94      0.881\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    112/150      10.7G     0.4115     0.3668     0.9172         41        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.893      0.926      0.942      0.873\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    113/150      10.5G     0.4086     0.3227      0.886         34        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.895      0.911      0.942      0.863\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    114/150      10.6G     0.3702     0.2969     0.8862         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.904      0.893      0.942      0.855\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    115/150      10.5G     0.4268     0.3352     0.9157         36        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.904      0.898       0.94      0.869\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    116/150      10.7G     0.3924     0.2927     0.8555         34        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.907      0.933      0.942      0.866\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    117/150      10.5G     0.3903     0.2961     0.8929         35        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.894      0.933      0.942      0.874\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    118/150      10.7G     0.3931     0.2951     0.8972         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.838      0.871      0.904      0.798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    119/150      10.5G     0.3823     0.3232     0.8976         34        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.848      0.867      0.903      0.793\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    120/150      10.6G     0.4216     0.3273     0.8886         48        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.861      0.862      0.886      0.811\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    121/150      10.5G     0.3909      0.298     0.8807         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.852      0.867      0.885      0.811\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    122/150      10.6G     0.3701      0.287     0.8747         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.844      0.872      0.902      0.804\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    123/150      10.5G     0.3726      0.292     0.8746         33        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.821      0.867      0.886      0.791\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    124/150      10.6G     0.3467     0.2844     0.8566         42        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12        0.9      0.857       0.92      0.855\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    125/150      10.5G     0.3564     0.2829     0.8818         25        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.877      0.845       0.92      0.873\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    126/150      10.6G      0.364     0.2869     0.8857         33        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.829      0.859       0.89      0.834\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    127/150      10.5G     0.3448     0.2735     0.8663         27        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.828      0.858       0.89      0.824\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    128/150      10.6G     0.3591     0.2904      0.867         48        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.823      0.855      0.893      0.832\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    129/150      10.8G     0.3516     0.2818     0.8669         53        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.831      0.857      0.893      0.841\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    130/150      10.6G      0.368     0.2942     0.8722         36        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.854       0.85       0.89      0.825\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    131/150      10.5G     0.3704     0.2963     0.8816         27        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.868      0.858      0.893      0.817\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    132/150      10.7G     0.3459     0.2779     0.8686         27        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.897      0.867      0.896      0.814\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    133/150      10.5G     0.3722     0.2845     0.8824         32        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.905      0.866      0.896      0.806\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    134/150      10.6G     0.3771     0.2788     0.9002         37        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.903      0.863      0.896      0.812\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    135/150      10.8G     0.3744     0.2791     0.8984         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.896      0.859      0.893       0.81\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    136/150      10.6G     0.3066     0.2513     0.8573         28        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.838      0.859      0.893      0.839\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    137/150      10.5G     0.3249     0.2676     0.8579         59        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12       0.83      0.858      0.893      0.832\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    138/150      10.6G     0.3299     0.2665     0.8539         41        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.828      0.858      0.893      0.832\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    139/150      10.5G     0.3113     0.2582     0.8455         54        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.831      0.859      0.893      0.833\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    140/150      10.7G      0.312     0.2507     0.8561         29        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.837      0.861      0.893      0.826\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    141/150      10.5G     0.3055     0.2292      0.844         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.843      0.863      0.893      0.832\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    142/150      10.6G     0.2538     0.1962     0.8178         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.843      0.867      0.893      0.833\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    143/150      10.5G     0.2342     0.1892     0.8054         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.842      0.867      0.926      0.854\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    144/150      10.6G     0.2523      0.189      0.808         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.845      0.866       0.89      0.829\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    145/150      10.8G     0.2323     0.1907     0.7993         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.844      0.863      0.889      0.819\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    146/150      10.6G      0.232     0.1904     0.8052         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.843       0.86      0.855      0.798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    147/150      10.8G      0.233     0.1843     0.8227         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.843      0.859      0.855      0.787\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    148/150      10.6G      0.244     0.2132     0.8205          4        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.843       0.86      0.857      0.799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    149/150      10.5G     0.2375     0.1936     0.8103         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.843       0.86      0.857      0.799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    150/150      10.7G      0.247     0.1976      0.804         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.843      0.861      0.857      0.799\n",
      "\n",
      "150 epochs completed in 0.067 hours.\n",
      "Optimizer stripped from runs/detect/train/weights/last.pt, 87.6MB\n",
      "Optimizer stripped from runs/detect/train/weights/best.pt, 87.6MB\n",
      "\n",
      "Validating runs/detect/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.14 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 4090, 24195MiB)\n",
      "Model summary (fused): 268 layers, 43610463 parameters, 0 gradients, 164.8 GFLOPs\n",
      "/home/nicolastovantrang/Desktop/sew/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          4         12      0.803      0.954      0.962      0.891\n",
      "                 Box3G          4          3          1      0.816      0.995      0.895\n",
      "                 Box4G          4          2      0.599          1      0.995      0.899\n",
      "                 Box8G          4          2      0.846          1      0.995      0.927\n",
      "                 BoxB4          4          2      0.652      0.956      0.828      0.767\n",
      "                 BoxB8          4          3      0.921          1      0.995      0.967\n",
      "Speed: 0.1ms preprocess, 1.8ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
      "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    }
   ],
   "source": [
    "!yolo mode=train model=yolov8l.pt data={path}/data.yaml epochs=150 imgsz=640 batch=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'runs\\\\detect\\\\train\\\\weights\\\\best.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mruns/detect/train/weights/best.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ultralytics\\models\\yolo\\model.py:23\u001b[0m, in \u001b[0;36mYOLO.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m new_instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ultralytics\\engine\\model.py:151\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(model, task\u001b[38;5;241m=\u001b[39mtask, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 151\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ultralytics\\engine\\model.py:240\u001b[0m, in \u001b[0;36mModel._load\u001b[1;34m(self, weights, task)\u001b[0m\n\u001b[0;32m    237\u001b[0m weights \u001b[38;5;241m=\u001b[39m checks\u001b[38;5;241m.\u001b[39mcheck_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolov8n -> yolov8n.pt\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(weights)\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;241m=\u001b[39m \u001b[43mattempt_load_one_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_ckpt_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ultralytics\\nn\\tasks.py:806\u001b[0m, in \u001b[0;36mattempt_load_one_weight\u001b[1;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattempt_load_one_weight\u001b[39m(weight, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fuse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    805\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a single model weights.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 806\u001b[0m     ckpt, weight \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[0;32m    807\u001b[0m     args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mDEFAULT_CFG_DICT, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[0;32m    808\u001b[0m     model \u001b[38;5;241m=\u001b[39m (ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ultralytics\\nn\\tasks.py:732\u001b[0m, in \u001b[0;36mtorch_safe_load\u001b[1;34m(weight)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    725\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m temporary_modules(\n\u001b[0;32m    726\u001b[0m         {\n\u001b[0;32m    727\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124multralytics.yolo.utils\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124multralytics.utils\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    730\u001b[0m         }\n\u001b[0;32m    731\u001b[0m     ):  \u001b[38;5;66;03m# for legacy 8.0 Classify and Pose models\u001b[39;00m\n\u001b[1;32m--> 732\u001b[0m         ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'runs\\\\detect\\\\train\\\\weights\\\\best.pt'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"runs/detect/train/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from supervision.annotators.base import BaseAnnotator, ImageType\n",
    "from supervision.annotators.utils import ColorLookup, resolve_color\n",
    "from supervision.detection.core import Detections\n",
    "from supervision.draw.color import Color, ColorPalette\n",
    "from supervision.utils.conversion import convert_for_annotation_method\n",
    "import cv2\n",
    "\n",
    "\n",
    "class MyAnnotator(BaseAnnotator):\n",
    "    \"\"\"\n",
    "    A class for drawing bounding boxes on an image using provided detections.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        color: Union[\"Color\", \"ColorPalette\"] = ColorPalette.DEFAULT,\n",
    "        thickness: int = 2,\n",
    "        color_lookup: ColorLookup = ColorLookup.CLASS,\n",
    "    ):\n",
    "        self.color: Union[Color, ColorPalette] = color\n",
    "        self.thickness: int = thickness\n",
    "        self.color_lookup: ColorLookup = color_lookup\n",
    "\n",
    "    @convert_for_annotation_method\n",
    "    def annotate(\n",
    "        self,\n",
    "        scene: ImageType,\n",
    "        detections: Detections,\n",
    "        custom_color_lookup: Optional[np.ndarray] = None,\n",
    "    ) -> ImageType:\n",
    "        mydict = {}\n",
    "        color_dict = {}\n",
    "\n",
    "        for detection_idx in range(len(detections)):\n",
    "            x1, y1, x2, y2 = detections.xyxy[detection_idx].astype(int)\n",
    "            color = resolve_color(\n",
    "                color=self.color,\n",
    "                detections=detections,\n",
    "                detection_idx=detection_idx,\n",
    "                color_lookup=self.color_lookup if custom_color_lookup is None else custom_color_lookup,\n",
    "            )\n",
    "            cv2.rectangle(\n",
    "                img=scene,\n",
    "                pt1=(x1, y1),\n",
    "                pt2=(x2, y2),\n",
    "                color=color.as_bgr(),\n",
    "                thickness=self.thickness,\n",
    "            )\n",
    "\n",
    "            class_guessed = detections.class_id[detection_idx]\n",
    "            if class_guessed not in mydict:\n",
    "                mydict[class_guessed] = 0\n",
    "            mydict[class_guessed] += 1\n",
    "            color_dict[class_guessed] = color\n",
    "\n",
    "        keys = list(mydict.keys())\n",
    "\n",
    "        for i in range(len(mydict)):\n",
    "            key = keys[i]\n",
    "            classname = model.model.names[key]\n",
    "            # draw first time in black\n",
    "            cv2.putText(\n",
    "                scene,\n",
    "                f\"{classname}: {mydict[key]}\",\n",
    "                (10, 60 + i * 60),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                2,\n",
    "                (0, 0, 0),\n",
    "                4,\n",
    "                cv2.LINE_AA,\n",
    "            )\n",
    "            cv2.putText(\n",
    "                scene,\n",
    "                f\"{classname}: {mydict[key]}\",\n",
    "                (10, 60 + i * 60),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                2,\n",
    "                color_dict[key].as_bgr(),\n",
    "                4,\n",
    "                cv2.LINE_AA,\n",
    "            )\n",
    "\n",
    "        return scene\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[0;32m     25\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(image, (\u001b[38;5;241m1280\u001b[39m, \u001b[38;5;241m1280\u001b[39m))\n\u001b[1;32m---> 26\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(image, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, iou\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m, conf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     27\u001b[0m detections \u001b[38;5;241m=\u001b[39m sv\u001b[38;5;241m.\u001b[39mDetections\u001b[38;5;241m.\u001b[39mfrom_ultralytics(results)\n\u001b[0;32m     28\u001b[0m labels \u001b[38;5;241m=\u001b[39m [model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnames[class_id] \u001b[38;5;28;01mfor\u001b[39;00m class_id \u001b[38;5;129;01min\u001b[39;00m detections\u001b[38;5;241m.\u001b[39mclass_id]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import supervision as sv\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "bounding_box_annotator = MyAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "image_paths = glob.glob(f\"{path}/test/images/*.jpg\")\n",
    "num_images = len(image_paths)\n",
    "\n",
    "# Determine the number of grids\n",
    "num_grids = math.ceil(num_images / 9)\n",
    "\n",
    "# Iterate over each grid\n",
    "for grid in range(num_grids):\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(15, 15))  # Create a 3x3 grid of subplots\n",
    "\n",
    "    # Get the images for this grid\n",
    "    grid_image_paths = image_paths[grid * 9 : (grid + 1) * 9]\n",
    "\n",
    "    for ax, image_path in zip(axs.flatten(), grid_image_paths):\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, (1280, 1280))\n",
    "        results = model.predict(image, verbose=False, iou=0.4, conf=0.3)[0]\n",
    "        detections = sv.Detections.from_ultralytics(results)\n",
    "        labels = [model.model.names[class_id] for class_id in detections.class_id]\n",
    "        annotated_image = bounding_box_annotator.annotate(scene=image, detections=detections)\n",
    "        annotated_image = label_annotator.annotate(scene=annotated_image, detections=detections, labels=labels)\n",
    "        ax.imshow(cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB))\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.47 🚀 Python-3.10.12 torch-2.2.2+cu121 CUDA:0 (NVIDIA GeForce RTX 4090, 24195MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/nicolastovantrang/Desktop/sew/YOLO/Box-Counting-6/valid/labels.cache... 14 images, 0 backgrounds, 0 corrupt: 100%|██████████| 14/14 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         14        100      0.911      0.928      0.944      0.639\n",
      "                 Box4G         14         28      0.854          1      0.956      0.823\n",
      "                 Box8G         14         22       0.91          1      0.942      0.619\n",
      "                 BoxB4         14         32      0.882          1      0.973       0.69\n",
      "                 BoxB8         14         18          1      0.712      0.904      0.424\n",
      "Speed: 0.1ms preprocess, 12.5ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0, 1, 2, 3])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7f76f4190ac0>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,       0.875,       0.875,           0],\n",
       "       [          1,           1,           1, ...,     0.91667,     0.91667,           0],\n",
       "       [          1,           1,           1, ...,     0.91429,     0.91429,           0],\n",
       "       [          1,           1,           1, ...,     0.43902,     0.43902,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.74667,     0.74667,     0.82856, ...,           0,           0,           0],\n",
       "       [    0.72131,     0.72131,     0.76021, ...,           0,           0,           0],\n",
       "       [     0.7033,      0.7033,     0.79078, ...,           0,           0,           0],\n",
       "       [    0.43373,     0.43373,     0.48898, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.59574,     0.59574,      0.7073, ...,           1,           1,           1],\n",
       "       [     0.5641,      0.5641,     0.61318, ...,           1,           1,           1],\n",
       "       [    0.54237,     0.54237,     0.65396, ...,           1,           1,           1],\n",
       "       [    0.27692,     0.27692,     0.32361, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,           0,           0,           0],\n",
       "       [          1,           1,           1, ...,           0,           0,           0],\n",
       "       [          1,           1,           1, ...,           0,           0,           0],\n",
       "       [          1,           1,           1, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: 0.6695239844062234\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.82279,     0.61884,     0.69028,     0.42433])\n",
       "names: {0: 'Box4G', 1: 'Box8G', 2: 'BoxB4', 3: 'BoxB8'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.911384064019035, 'metrics/recall(B)': 0.9280632820428872, 'metrics/mAP50(B)': 0.9437077222604375, 'metrics/mAP50-95(B)': 0.6390591246446441, 'fitness': 0.6695239844062234}\n",
       "save_dir: PosixPath('runs/detect/val')\n",
       "speed: {'preprocess': 0.09168897356305804, 'inference': 12.479679925101143, 'loss': 0.0003235680716378348, 'postprocess': 0.24565628596714564}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.val()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video rendering\n",
    "\n",
    "## Used to generate annotated video from model and video.\n",
    "\n",
    "When the model is not fast enough to run in real-time, it can be useful to generate a video with the model's predictions.\n",
    "Showing its strength and weaknesses in a more visual way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nicol\\anaconda3\\envs\\pytorch\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nicol\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 761, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\nicol\\anaconda3\\envs\\pytorch\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_22152\\3712991363.py\", line 31, in read_frames\n",
      "cv2.error: Unknown C++ exception from OpenCV code\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import queue\n",
    "import os\n",
    "\n",
    "# Create the 'output' directory if it doesn't exist\n",
    "import threading\n",
    "path = r\"output_good2\"\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Open the video stream\n",
    "stream = cv2.VideoCapture(\"rtsp://root:sewusocome@192.168.15.56/axis-media/media.amp\")\n",
    "\n",
    "# Get the video properties\n",
    "width = int(stream.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(stream.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = stream.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Set the segment duration to 30 seconds\n",
    "segment_duration = 10  # in seconds\n",
    "\n",
    "# Initialize the file index\n",
    "file_index = 1\n",
    "\n",
    "frame_queue = queue.Queue(maxsize=10)\n",
    "\n",
    "\n",
    "def read_frames():\n",
    "    global stream\n",
    "    while True:\n",
    "        ret, frame = stream.read()\n",
    "        if ret:\n",
    "            try:\n",
    "                frame_queue.put(frame, block=False)\n",
    "            except queue.Full:\n",
    "                pass\n",
    "\n",
    "\n",
    "# start a thread to read frames\n",
    "thread = threading.Thread(target=read_frames)\n",
    "thread.start()\n",
    "\n",
    "\n",
    "for i in range(1):\n",
    "    # Create a video writer to save the video segment\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(\n",
    "        f'{path}/output_{file_index:03d}.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "    # Record the video segment\n",
    "    start_time = cv2.getTickCount()\n",
    "    while (cv2.getTickCount() - start_time) / cv2.getTickFrequency() < segment_duration:\n",
    "        try:\n",
    "            frame = frame_queue.get(block=False)\n",
    "            out.write(frame)\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "\n",
    "    # Release the video writer\n",
    "    out.release()\n",
    "\n",
    "    # Increment the file index\n",
    "    file_index += 1\n",
    "\n",
    "\n",
    "# Release the video capture\n",
    "stream.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def read_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "\n",
    "def save_video(output_video_frames, output_video_path):\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, 24, (output_video_frames[0].shape[1], output_video_frames[0].shape[0]))\n",
    "    for frame in output_video_frames:\n",
    "        out.write(frame)\n",
    "    out.release()\n",
    "\n",
    "\n",
    "bounding_box_annotator = sv.BoundingBoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "\n",
    "def render_video(video_path, output_video_path, model):\n",
    "    if not os.path.exists(video_path):\n",
    "        raise FileNotFoundError(f\"File {video_path} does not exist\")\n",
    "    frames = read_video(video_path)\n",
    "    output_video_frames = []\n",
    "    for frame in tqdm(frames, desc=\"Processing frames\"):\n",
    "        frame = cv2.resize(frame, (640, 640))\n",
    "        results = model(frame)[0]\n",
    "        detections = sv.Detections.from_ultralytics(results)\n",
    "        labels = [model.model.names[class_id] for class_id in detections.class_id]\n",
    "        annotated_frame = bounding_box_annotator.annotate(scene=frame, detections=detections)\n",
    "        annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections, labels=labels)\n",
    "        output_video_frames.append(annotated_frame)\n",
    "    save_video(output_video_frames, output_video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:   0%|          | 0/297 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 8 Box8Gs, 6 BoxB4s, 11 BoxB8s, 49.0ms\n",
      "Speed: 0.0ms preprocess, 49.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:   0%|          | 1/297 [00:00<04:49,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 Box4G, 9 Box8Gs, 5 BoxB4s, 11 BoxB8s, 52.0ms\n",
      "Speed: 0.0ms preprocess, 52.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box4G, 9 Box8Gs, 7 BoxB4s, 10 BoxB8s, 53.9ms\n",
      "Speed: 0.0ms preprocess, 53.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:   1%|          | 3/297 [00:01<01:27,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 Box4G, 7 Box8Gs, 6 BoxB4s, 10 BoxB8s, 30.1ms\n",
      "Speed: 2.9ms preprocess, 30.1ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box4G, 8 Box8Gs, 4 BoxB4s, 10 BoxB8s, 30.1ms\n",
      "Speed: 3.1ms preprocess, 30.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 7 Box8Gs, 3 BoxB4s, 10 BoxB8s, 31.1ms\n",
      "Speed: 2.0ms preprocess, 31.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:   2%|▏         | 6/297 [00:01<00:41,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 8 Box8Gs, 5 BoxB4s, 10 BoxB8s, 29.7ms\n",
      "Speed: 6.0ms preprocess, 29.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 7 Box8Gs, 5 BoxB4s, 10 BoxB8s, 32.7ms\n",
      "Speed: 3.8ms preprocess, 32.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box4G, 7 Box8Gs, 3 BoxB4s, 11 BoxB8s, 23.3ms\n",
      "Speed: 1.9ms preprocess, 23.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:   3%|▎         | 9/297 [00:01<00:28, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 Box4G, 8 Box8Gs, 4 BoxB4s, 10 BoxB8s, 33.4ms\n",
      "Speed: 0.0ms preprocess, 33.4ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box4G, 9 Box8Gs, 3 BoxB4s, 10 BoxB8s, 33.2ms\n",
      "Speed: 0.0ms preprocess, 33.2ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box4G, 10 Box8Gs, 3 BoxB4s, 10 BoxB8s, 35.4ms\n",
      "Speed: 0.0ms preprocess, 35.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:   4%|▍         | 12/297 [00:01<00:22, 12.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 Box4G, 6 Box8Gs, 3 BoxB4s, 10 BoxB8s, 36.8ms\n",
      "Speed: 0.0ms preprocess, 36.8ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box4G, 9 Box8Gs, 3 BoxB4s, 11 BoxB8s, 33.4ms\n",
      "Speed: 0.0ms preprocess, 33.4ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 Box8Gs, 3 BoxB4s, 10 BoxB8s, 37.4ms\n",
      "Speed: 0.0ms preprocess, 37.4ms inference, 6.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:   5%|▌         | 15/297 [00:01<00:18, 15.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 Box4G, 5 Box8Gs, 3 BoxB4s, 10 BoxB8s, 30.2ms\n",
      "Speed: 2.1ms preprocess, 30.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 7 Box8Gs, 3 BoxB4s, 9 BoxB8s, 36.1ms\n",
      "Speed: 0.0ms preprocess, 36.1ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box8G, 3 BoxB4s, 11 BoxB8s, 30.8ms\n",
      "Speed: 2.5ms preprocess, 30.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:   6%|▌         | 18/297 [00:01<00:16, 17.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 6 Box8Gs, 3 BoxB4s, 9 BoxB8s, 29.6ms\n",
      "Speed: 4.5ms preprocess, 29.6ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Box8Gs, 3 BoxB4s, 7 BoxB8s, 33.3ms\n",
      "Speed: 0.6ms preprocess, 33.3ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 7 Box8Gs, 3 BoxB4s, 7 BoxB8s, 29.2ms\n",
      "Speed: 2.2ms preprocess, 29.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:   7%|▋         | 21/297 [00:01<00:15, 18.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 Box8Gs, 3 BoxB4s, 6 BoxB8s, 30.0ms\n",
      "Speed: 5.5ms preprocess, 30.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 Box8Gs, 4 BoxB4s, 9 BoxB8s, 29.3ms\n",
      "Speed: 4.2ms preprocess, 29.3ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 Box8Gs, 3 BoxB4s, 9 BoxB8s, 28.0ms\n",
      "Speed: 2.8ms preprocess, 28.0ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:   8%|▊         | 24/297 [00:02<00:13, 19.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 5 Box8Gs, 3 BoxB4s, 9 BoxB8s, 32.9ms\n",
      "Speed: 0.7ms preprocess, 32.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 Box8Gs, 3 BoxB4s, 7 BoxB8s, 29.5ms\n",
      "Speed: 3.8ms preprocess, 29.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 Box8Gs, 3 BoxB4s, 8 BoxB8s, 27.4ms\n",
      "Speed: 3.0ms preprocess, 27.4ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:   9%|▉         | 27/297 [00:02<00:13, 20.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 5 Box8Gs, 3 BoxB4s, 8 BoxB8s, 30.8ms\n",
      "Speed: 3.7ms preprocess, 30.8ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 7 Box8Gs, 3 BoxB4s, 6 BoxB8s, 29.9ms\n",
      "Speed: 3.0ms preprocess, 29.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Box8Gs, 3 BoxB4s, 7 BoxB8s, 30.2ms\n",
      "Speed: 4.6ms preprocess, 30.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  10%|█         | 30/297 [00:02<00:12, 20.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 6 Box8Gs, 5 BoxB4s, 5 BoxB8s, 29.1ms\n",
      "Speed: 4.1ms preprocess, 29.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 7 Box8Gs, 6 BoxB4s, 6 BoxB8s, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Box8Gs, 9 BoxB4s, 3 BoxB8s, 28.6ms\n",
      "Speed: 2.5ms preprocess, 28.6ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  11%|█         | 33/297 [00:02<00:12, 21.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 10 Box8Gs, 9 BoxB4s, 1 BoxB8, 44.2ms\n",
      "Speed: 0.0ms preprocess, 44.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Box8Gs, 7 BoxB4s, 5 BoxB8s, 37.4ms\n",
      "Speed: 0.0ms preprocess, 37.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 Box8Gs, 8 BoxB4s, 5 BoxB8s, 35.3ms\n",
      "Speed: 0.0ms preprocess, 35.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  12%|█▏        | 36/297 [00:02<00:12, 21.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 12 Box8Gs, 7 BoxB4s, 3 BoxB8s, 32.9ms\n",
      "Speed: 12.6ms preprocess, 32.9ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Box8Gs, 9 BoxB4s, 4 BoxB8s, 32.8ms\n",
      "Speed: 0.5ms preprocess, 32.8ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 6 Box8Gs, 9 BoxB4s, 1 BoxB8, 30.5ms\n",
      "Speed: 4.6ms preprocess, 30.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  13%|█▎        | 39/297 [00:02<00:12, 20.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 10 Box8Gs, 9 BoxB4s, 3 BoxB8s, 32.3ms\n",
      "Speed: 0.7ms preprocess, 32.3ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Box8Gs, 10 BoxB4s, 3 BoxB8s, 26.7ms\n",
      "Speed: 5.1ms preprocess, 26.7ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 Box8Gs, 9 BoxB4s, 39.9ms\n",
      "Speed: 0.0ms preprocess, 39.9ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  14%|█▍        | 42/297 [00:02<00:12, 20.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 Box8Gs, 9 BoxB4s, 4 BoxB8s, 30.3ms\n",
      "Speed: 4.3ms preprocess, 30.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 10 Box8Gs, 10 BoxB4s, 2 BoxB8s, 31.0ms\n",
      "Speed: 4.5ms preprocess, 31.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 Box8Gs, 9 BoxB4s, 3 BoxB8s, 32.7ms\n",
      "Speed: 0.6ms preprocess, 32.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  15%|█▌        | 45/297 [00:03<00:12, 20.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 8 Box8Gs, 10 BoxB4s, 4 BoxB8s, 31.2ms\n",
      "Speed: 4.1ms preprocess, 31.2ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 Box8Gs, 9 BoxB4s, 2 BoxB8s, 28.9ms\n",
      "Speed: 6.3ms preprocess, 28.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 Box8Gs, 9 BoxB4s, 2 BoxB8s, 33.8ms\n",
      "Speed: 0.0ms preprocess, 33.8ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  16%|█▌        | 48/297 [00:03<00:12, 20.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 6 Box8Gs, 8 BoxB4s, 3 BoxB8s, 33.9ms\n",
      "Speed: 0.0ms preprocess, 33.9ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Box8Gs, 11 BoxB4s, 4 BoxB8s, 29.1ms\n",
      "Speed: 4.3ms preprocess, 29.1ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 Box8Gs, 6 BoxB4s, 3 BoxB8s, 34.2ms\n",
      "Speed: 0.0ms preprocess, 34.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  17%|█▋        | 51/297 [00:03<00:11, 20.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 Box8G, 3 BoxB4s, 2 BoxB8s, 31.5ms\n",
      "Speed: 2.0ms preprocess, 31.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Box8Gs, 4 BoxB4s, 3 BoxB8s, 38.3ms\n",
      "Speed: 0.0ms preprocess, 38.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 7 Box8Gs, 4 BoxB4s, 6 BoxB8s, 33.0ms\n",
      "Speed: 0.0ms preprocess, 33.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  18%|█▊        | 54/297 [00:03<00:11, 21.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 Box8G, 4 BoxB4s, 4 BoxB8s, 33.3ms\n",
      "Speed: 1.0ms preprocess, 33.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Box8Gs, 4 BoxB4s, 6 BoxB8s, 33.3ms\n",
      "Speed: 0.0ms preprocess, 33.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Box8Gs, 4 BoxB4s, 6 BoxB8s, 29.0ms\n",
      "Speed: 4.2ms preprocess, 29.0ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  19%|█▉        | 57/297 [00:03<00:10, 21.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 Box8Gs, 4 BoxB4s, 6 BoxB8s, 31.9ms\n",
      "Speed: 4.1ms preprocess, 31.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box8G, 4 BoxB4s, 5 BoxB8s, 33.1ms\n",
      "Speed: 0.0ms preprocess, 33.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Box8Gs, 4 BoxB4s, 4 BoxB8s, 33.6ms\n",
      "Speed: 0.0ms preprocess, 33.6ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  20%|██        | 60/297 [00:03<00:10, 22.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 3 Box8Gs, 3 BoxB4s, 4 BoxB8s, 38.1ms\n",
      "Speed: 0.0ms preprocess, 38.1ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Box8Gs, 3 BoxB4s, 7 BoxB8s, 33.2ms\n",
      "Speed: 0.0ms preprocess, 33.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Box8Gs, 3 BoxB4s, 8 BoxB8s, 33.2ms\n",
      "Speed: 0.0ms preprocess, 33.2ms inference, 8.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  21%|██        | 63/297 [00:03<00:10, 22.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 Box8G, 4 BoxB4s, 9 BoxB8s, 31.7ms\n",
      "Speed: 10.6ms preprocess, 31.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box8G, 4 BoxB4s, 10 BoxB8s, 33.3ms\n",
      "Speed: 0.5ms preprocess, 33.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Box8Gs, 3 BoxB4s, 10 BoxB8s, 29.3ms\n",
      "Speed: 12.3ms preprocess, 29.3ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  22%|██▏       | 66/297 [00:03<00:10, 22.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 3 BoxB4s, 10 BoxB8s, 31.0ms\n",
      "Speed: 10.4ms preprocess, 31.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box8G, 3 BoxB4s, 9 BoxB8s, 29.2ms\n",
      "Speed: 8.1ms preprocess, 29.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 BoxB4s, 13 BoxB8s, 33.6ms\n",
      "Speed: 0.0ms preprocess, 33.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  23%|██▎       | 69/297 [00:04<00:10, 22.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 Box8G, 3 BoxB4s, 9 BoxB8s, 34.8ms\n",
      "Speed: 0.0ms preprocess, 34.8ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Box8Gs, 4 BoxB4s, 13 BoxB8s, 33.3ms\n",
      "Speed: 0.0ms preprocess, 33.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 BoxB4s, 14 BoxB8s, 45.8ms\n",
      "Speed: 0.0ms preprocess, 45.8ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  24%|██▍       | 72/297 [00:04<00:10, 22.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 Box8G, 3 BoxB4s, 11 BoxB8s, 29.4ms\n",
      "Speed: 3.7ms preprocess, 29.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Box8Gs, 5 BoxB4s, 10 BoxB8s, 29.1ms\n",
      "Speed: 0.0ms preprocess, 29.1ms inference, 12.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Box8Gs, 3 BoxB4s, 9 BoxB8s, 39.1ms\n",
      "Speed: 0.0ms preprocess, 39.1ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  25%|██▌       | 75/297 [00:04<00:09, 22.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 3 Box8Gs, 4 BoxB4s, 11 BoxB8s, 32.3ms\n",
      "Speed: 0.5ms preprocess, 32.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box8G, 4 BoxB4s, 11 BoxB8s, 30.1ms\n",
      "Speed: 3.0ms preprocess, 30.1ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box8G, 4 BoxB4s, 9 BoxB8s, 21.0ms\n",
      "Speed: 3.7ms preprocess, 21.0ms inference, 11.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  26%|██▋       | 78/297 [00:04<00:09, 22.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 Box8G, 7 BoxB4s, 12 BoxB8s, 33.6ms\n",
      "Speed: 0.7ms preprocess, 33.6ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box8G, 5 BoxB4s, 13 BoxB8s, 30.8ms\n",
      "Speed: 3.0ms preprocess, 30.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Box8Gs, 7 BoxB4s, 10 BoxB8s, 31.9ms\n",
      "Speed: 0.5ms preprocess, 31.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  27%|██▋       | 81/297 [00:04<00:09, 22.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 Box8G, 5 BoxB4s, 11 BoxB8s, 30.9ms\n",
      "Speed: 2.6ms preprocess, 30.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Box8Gs, 6 BoxB4s, 10 BoxB8s, 33.3ms\n",
      "Speed: 0.0ms preprocess, 33.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Box8Gs, 5 BoxB4s, 11 BoxB8s, 29.1ms\n",
      "Speed: 4.1ms preprocess, 29.1ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  28%|██▊       | 84/297 [00:04<00:09, 22.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 Box8G, 4 BoxB4s, 12 BoxB8s, 33.2ms\n",
      "Speed: 0.0ms preprocess, 33.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Box8Gs, 5 BoxB4s, 11 BoxB8s, 31.5ms\n",
      "Speed: 4.2ms preprocess, 31.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Box8Gs, 4 BoxB4s, 13 BoxB8s, 28.9ms\n",
      "Speed: 3.0ms preprocess, 28.9ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  29%|██▉       | 87/297 [00:04<00:09, 22.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 Box8G, 5 BoxB4s, 10 BoxB8s, 31.8ms\n",
      "Speed: 4.1ms preprocess, 31.8ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 BoxB4s, 12 BoxB8s, 29.0ms\n",
      "Speed: 4.2ms preprocess, 29.0ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 7 BoxB4s, 11 BoxB8s, 32.8ms\n",
      "Speed: 0.5ms preprocess, 32.8ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  30%|███       | 90/297 [00:05<00:09, 22.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 Box8Gs, 6 BoxB4s, 11 BoxB8s, 30.7ms\n",
      "Speed: 3.0ms preprocess, 30.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box8G, 5 BoxB4s, 11 BoxB8s, 33.2ms\n",
      "Speed: 0.0ms preprocess, 33.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box8G, 5 BoxB4s, 10 BoxB8s, 29.1ms\n",
      "Speed: 4.2ms preprocess, 29.1ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  31%|███▏      | 93/297 [00:05<00:09, 22.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 BoxB4s, 12 BoxB8s, 30.6ms\n",
      "Speed: 2.0ms preprocess, 30.6ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 BoxB4s, 13 BoxB8s, 29.7ms\n",
      "Speed: 2.9ms preprocess, 29.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 BoxB4s, 12 BoxB8s, 31.3ms\n",
      "Speed: 1.8ms preprocess, 31.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  32%|███▏      | 96/297 [00:05<00:09, 22.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 5 BoxB4s, 13 BoxB8s, 32.0ms\n",
      "Speed: 2.7ms preprocess, 32.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 BoxB4s, 14 BoxB8s, 30.9ms\n",
      "Speed: 5.7ms preprocess, 30.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 BoxB4s, 14 BoxB8s, 31.0ms\n",
      "Speed: 2.9ms preprocess, 31.0ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  33%|███▎      | 99/297 [00:05<00:08, 22.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 BoxB4s, 14 BoxB8s, 31.4ms\n",
      "Speed: 2.1ms preprocess, 31.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 BoxB4s, 13 BoxB8s, 31.5ms\n",
      "Speed: 3.0ms preprocess, 31.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 BoxB4s, 11 BoxB8s, 30.6ms\n",
      "Speed: 2.9ms preprocess, 30.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  34%|███▍      | 102/297 [00:05<00:08, 22.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 BoxB4s, 13 BoxB8s, 34.1ms\n",
      "Speed: 0.0ms preprocess, 34.1ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 BoxB4s, 13 BoxB8s, 33.3ms\n",
      "Speed: 0.0ms preprocess, 33.3ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 BoxB4s, 15 BoxB8s, 30.2ms\n",
      "Speed: 6.1ms preprocess, 30.2ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  35%|███▌      | 105/297 [00:05<00:08, 21.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 BoxB4s, 12 BoxB8s, 32.9ms\n",
      "Speed: 0.0ms preprocess, 32.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 BoxB4s, 13 BoxB8s, 28.8ms\n",
      "Speed: 4.3ms preprocess, 28.8ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 BoxB4s, 12 BoxB8s, 31.5ms\n",
      "Speed: 0.6ms preprocess, 31.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  36%|███▋      | 108/297 [00:05<00:08, 22.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 5 BoxB4s, 11 BoxB8s, 46.0ms\n",
      "Speed: 0.0ms preprocess, 46.0ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 BoxB4s, 13 BoxB8s, 29.5ms\n",
      "Speed: 3.5ms preprocess, 29.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 BoxB4s, 14 BoxB8s, 30.5ms\n",
      "Speed: 3.2ms preprocess, 30.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  37%|███▋      | 111/297 [00:06<00:08, 22.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 BoxB4s, 14 BoxB8s, 34.0ms\n",
      "Speed: 0.0ms preprocess, 34.0ms inference, 7.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 BoxB4s, 13 BoxB8s, 33.2ms\n",
      "Speed: 0.0ms preprocess, 33.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 BoxB4s, 13 BoxB8s, 34.0ms\n",
      "Speed: 0.0ms preprocess, 34.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  38%|███▊      | 114/297 [00:06<00:08, 21.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 BoxB4s, 12 BoxB8s, 30.9ms\n",
      "Speed: 4.2ms preprocess, 30.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 BoxB4s, 10 BoxB8s, 32.5ms\n",
      "Speed: 2.2ms preprocess, 32.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 BoxB4s, 12 BoxB8s, 33.9ms\n",
      "Speed: 0.0ms preprocess, 33.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  39%|███▉      | 117/297 [00:06<00:08, 22.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 BoxB4s, 13 BoxB8s, 31.2ms\n",
      "Speed: 3.1ms preprocess, 31.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 BoxB4s, 13 BoxB8s, 29.1ms\n",
      "Speed: 4.2ms preprocess, 29.1ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 BoxB4s, 12 BoxB8s, 32.6ms\n",
      "Speed: 4.5ms preprocess, 32.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  40%|████      | 120/297 [00:06<00:07, 22.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 3 BoxB4s, 12 BoxB8s, 30.2ms\n",
      "Speed: 4.3ms preprocess, 30.2ms inference, 7.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 BoxB4s, 12 BoxB8s, 31.9ms\n",
      "Speed: 0.4ms preprocess, 31.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 BoxB4s, 11 BoxB8s, 34.0ms\n",
      "Speed: 0.0ms preprocess, 34.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  41%|████▏     | 123/297 [00:06<00:07, 22.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 3 BoxB4s, 12 BoxB8s, 32.2ms\n",
      "Speed: 4.1ms preprocess, 32.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 6 BoxB4s, 14 BoxB8s, 33.4ms\n",
      "Speed: 0.0ms preprocess, 33.4ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 BoxB4s, 12 BoxB8s, 33.2ms\n",
      "Speed: 0.0ms preprocess, 33.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  42%|████▏     | 126/297 [00:06<00:07, 22.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 BoxB4s, 12 BoxB8s, 31.6ms\n",
      "Speed: 4.2ms preprocess, 31.6ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 BoxB4s, 11 BoxB8s, 29.0ms\n",
      "Speed: 4.2ms preprocess, 29.0ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 BoxB4s, 15 BoxB8s, 33.0ms\n",
      "Speed: 4.0ms preprocess, 33.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  43%|████▎     | 129/297 [00:06<00:07, 22.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 BoxB4s, 17 BoxB8s, 32.9ms\n",
      "Speed: 4.2ms preprocess, 32.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BoxB4, 17 BoxB8s, 37.6ms\n",
      "Speed: 0.0ms preprocess, 37.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 16 BoxB8s, 29.2ms\n",
      "Speed: 4.2ms preprocess, 29.2ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  44%|████▍     | 132/297 [00:06<00:07, 22.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 BoxB4s, 18 BoxB8s, 34.0ms\n",
      "Speed: 0.0ms preprocess, 34.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 BoxB4s, 17 BoxB8s, 30.5ms\n",
      "Speed: 3.4ms preprocess, 30.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BoxB4, 16 BoxB8s, 32.9ms\n",
      "Speed: 0.0ms preprocess, 32.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  45%|████▌     | 135/297 [00:07<00:07, 22.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 BoxB4, 15 BoxB8s, 38.7ms\n",
      "Speed: 0.0ms preprocess, 38.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box8G, 5 BoxB4s, 12 BoxB8s, 31.1ms\n",
      "Speed: 2.2ms preprocess, 31.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 BoxB4s, 15 BoxB8s, 31.4ms\n",
      "Speed: 2.4ms preprocess, 31.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  46%|████▋     | 138/297 [00:07<00:07, 22.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 6 BoxB4s, 15 BoxB8s, 29.8ms\n",
      "Speed: 3.4ms preprocess, 29.8ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 BoxB4s, 16 BoxB8s, 29.3ms\n",
      "Speed: 6.1ms preprocess, 29.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box4G, 4 BoxB4s, 16 BoxB8s, 31.1ms\n",
      "Speed: 1.6ms preprocess, 31.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  47%|████▋     | 141/297 [00:07<00:07, 22.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 Box4G, 4 BoxB4s, 15 BoxB8s, 33.0ms\n",
      "Speed: 0.0ms preprocess, 33.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box4G, 5 BoxB4s, 15 BoxB8s, 32.7ms\n",
      "Speed: 0.0ms preprocess, 32.7ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 BoxB4s, 15 BoxB8s, 41.6ms\n",
      "Speed: 0.0ms preprocess, 41.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  48%|████▊     | 144/297 [00:07<00:06, 22.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 BoxB4s, 14 BoxB8s, 39.9ms\n",
      "Speed: 0.0ms preprocess, 39.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box4G, 3 BoxB4s, 15 BoxB8s, 24.9ms\n",
      "Speed: 1.4ms preprocess, 24.9ms inference, 8.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box4G, 4 BoxB4s, 11 BoxB8s, 33.6ms\n",
      "Speed: 0.0ms preprocess, 33.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  49%|████▉     | 147/297 [00:07<00:06, 22.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 BoxB4s, 12 BoxB8s, 34.9ms\n",
      "Speed: 0.0ms preprocess, 34.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 BoxB4s, 11 BoxB8s, 29.0ms\n",
      "Speed: 0.3ms preprocess, 29.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 BoxB4s, 14 BoxB8s, 46.5ms\n",
      "Speed: 0.0ms preprocess, 46.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  51%|█████     | 150/297 [00:07<00:06, 22.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 BoxB4s, 11 BoxB8s, 30.3ms\n",
      "Speed: 0.3ms preprocess, 30.3ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BoxB4, 10 BoxB8s, 28.7ms\n",
      "Speed: 3.1ms preprocess, 28.7ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 BoxB4s, 10 BoxB8s, 33.3ms\n",
      "Speed: 0.0ms preprocess, 33.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  52%|█████▏    | 153/297 [00:07<00:06, 22.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 3 BoxB4s, 8 BoxB8s, 31.4ms\n",
      "Speed: 4.1ms preprocess, 31.4ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 BoxB4s, 10 BoxB8s, 29.4ms\n",
      "Speed: 3.7ms preprocess, 29.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 BoxB4s, 11 BoxB8s, 33.1ms\n",
      "Speed: 4.3ms preprocess, 33.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  53%|█████▎    | 156/297 [00:08<00:06, 22.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 3 BoxB4s, 12 BoxB8s, 31.1ms\n",
      "Speed: 0.9ms preprocess, 31.1ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 BoxB4s, 11 BoxB8s, 31.7ms\n",
      "Speed: 4.0ms preprocess, 31.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 BoxB4s, 8 BoxB8s, 29.5ms\n",
      "Speed: 3.7ms preprocess, 29.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  54%|█████▎    | 159/297 [00:08<00:06, 22.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 3 BoxB4s, 6 BoxB8s, 32.2ms\n",
      "Speed: 4.2ms preprocess, 32.2ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box8G, 4 BoxB4s, 7 BoxB8s, 29.3ms\n",
      "Speed: 3.1ms preprocess, 29.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 BoxB4s, 7 BoxB8s, 29.3ms\n",
      "Speed: 4.2ms preprocess, 29.3ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  55%|█████▍    | 162/297 [00:08<00:06, 22.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 BoxB4s, 5 BoxB8s, 32.0ms\n",
      "Speed: 4.2ms preprocess, 32.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 BoxB4s, 7 BoxB8s, 30.2ms\n",
      "Speed: 4.5ms preprocess, 30.2ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 BoxB4s, 6 BoxB8s, 31.7ms\n",
      "Speed: 4.2ms preprocess, 31.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  56%|█████▌    | 165/297 [00:08<00:05, 22.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 BoxB4, 5 BoxB8s, 33.8ms\n",
      "Speed: 0.0ms preprocess, 33.8ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BoxB4, 6 BoxB8s, 31.8ms\n",
      "Speed: 4.9ms preprocess, 31.8ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 BoxB4s, 6 BoxB8s, 31.0ms\n",
      "Speed: 4.2ms preprocess, 31.0ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  57%|█████▋    | 168/297 [00:08<00:05, 22.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 BoxB4, 4 BoxB8s, 42.4ms\n",
      "Speed: 0.0ms preprocess, 42.4ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BoxB4, 5 BoxB8s, 33.6ms\n",
      "Speed: 1.8ms preprocess, 33.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BoxB4, 4 BoxB8s, 29.0ms\n",
      "Speed: 4.1ms preprocess, 29.0ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  58%|█████▊    | 171/297 [00:08<00:05, 22.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 BoxB8s, 32.9ms\n",
      "Speed: 1.1ms preprocess, 32.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BoxB4, 4 BoxB8s, 33.2ms\n",
      "Speed: 0.0ms preprocess, 33.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BoxB4, 5 BoxB8s, 31.6ms\n",
      "Speed: 4.9ms preprocess, 31.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  59%|█████▊    | 174/297 [00:08<00:05, 22.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 BoxB4, 5 BoxB8s, 30.7ms\n",
      "Speed: 4.1ms preprocess, 30.7ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 BoxB4s, 4 BoxB8s, 31.7ms\n",
      "Speed: 4.1ms preprocess, 31.7ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 BoxB4s, 4 BoxB8s, 30.6ms\n",
      "Speed: 4.3ms preprocess, 30.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  60%|█████▉    | 177/297 [00:08<00:05, 22.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 3 BoxB4s, 4 BoxB8s, 32.7ms\n",
      "Speed: 0.7ms preprocess, 32.7ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 BoxB4s, 3 BoxB8s, 29.3ms\n",
      "Speed: 0.0ms preprocess, 29.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 BoxB4s, 3 BoxB8s, 31.9ms\n",
      "Speed: 15.5ms preprocess, 31.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  61%|██████    | 180/297 [00:09<00:05, 22.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 BoxB4s, 3 BoxB8s, 32.7ms\n",
      "Speed: 1.2ms preprocess, 32.7ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 BoxB4s, 3 BoxB8s, 28.5ms\n",
      "Speed: 3.3ms preprocess, 28.5ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 BoxB4s, 3 BoxB8s, 29.3ms\n",
      "Speed: 4.3ms preprocess, 29.3ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  62%|██████▏   | 183/297 [00:09<00:05, 22.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 BoxB4, 4 BoxB8s, 31.0ms\n",
      "Speed: 3.8ms preprocess, 31.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 BoxB4s, 4 BoxB8s, 29.6ms\n",
      "Speed: 3.4ms preprocess, 29.6ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 BoxB8s, 33.4ms\n",
      "Speed: 0.0ms preprocess, 33.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  63%|██████▎   | 186/297 [00:09<00:04, 22.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 BoxB8s, 30.6ms\n",
      "Speed: 4.0ms preprocess, 30.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BoxB4, 3 BoxB8s, 29.1ms\n",
      "Speed: 4.2ms preprocess, 29.1ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 BoxB8s, 29.3ms\n",
      "Speed: 4.1ms preprocess, 29.3ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  64%|██████▎   | 189/297 [00:09<00:04, 22.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 BoxB4, 3 BoxB8s, 32.5ms\n",
      "Speed: 2.0ms preprocess, 32.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BoxB4, 3 BoxB8s, 33.2ms\n",
      "Speed: 0.4ms preprocess, 33.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 BoxB4s, 3 BoxB8s, 33.5ms\n",
      "Speed: 0.0ms preprocess, 33.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  65%|██████▍   | 192/297 [00:09<00:04, 22.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 BoxB4s, 3 BoxB8s, 31.5ms\n",
      "Speed: 4.8ms preprocess, 31.5ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BoxB4, 3 BoxB8s, 29.5ms\n",
      "Speed: 4.0ms preprocess, 29.5ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BoxB4, 3 BoxB8s, 29.0ms\n",
      "Speed: 4.5ms preprocess, 29.0ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  66%|██████▌   | 195/297 [00:09<00:04, 22.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 BoxB4, 4 BoxB8s, 31.8ms\n",
      "Speed: 2.6ms preprocess, 31.8ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BoxB4, 3 BoxB8s, 32.1ms\n",
      "Speed: 2.6ms preprocess, 32.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 BoxB4s, 3 BoxB8s, 31.8ms\n",
      "Speed: 4.1ms preprocess, 31.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  67%|██████▋   | 198/297 [00:09<00:04, 22.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 BoxB4s, 4 BoxB8s, 31.2ms\n",
      "Speed: 3.7ms preprocess, 31.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 BoxB4s, 3 BoxB8s, 29.3ms\n",
      "Speed: 3.3ms preprocess, 29.3ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 BoxB4s, 4 BoxB8s, 33.0ms\n",
      "Speed: 4.5ms preprocess, 33.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  68%|██████▊   | 201/297 [00:10<00:04, 22.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 BoxB4s, 3 BoxB8s, 30.9ms\n",
      "Speed: 2.7ms preprocess, 30.9ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 BoxB4s, 4 BoxB8s, 32.7ms\n",
      "Speed: 0.0ms preprocess, 32.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 BoxB4s, 4 BoxB8s, 40.7ms\n",
      "Speed: 0.0ms preprocess, 40.7ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  69%|██████▊   | 204/297 [00:10<00:04, 21.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 BoxB4s, 4 BoxB8s, 31.0ms\n",
      "Speed: 4.2ms preprocess, 31.0ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 BoxB4s, 5 BoxB8s, 30.2ms\n",
      "Speed: 4.4ms preprocess, 30.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 BoxB4s, 7 BoxB8s, 33.3ms\n",
      "Speed: 0.0ms preprocess, 33.3ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  70%|██████▉   | 207/297 [00:10<00:04, 21.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 BoxB4, 8 BoxB8s, 29.8ms\n",
      "Speed: 4.2ms preprocess, 29.8ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BoxB4, 9 BoxB8s, 29.5ms\n",
      "Speed: 3.5ms preprocess, 29.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 BoxB8s, 29.1ms\n",
      "Speed: 4.2ms preprocess, 29.1ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  71%|███████   | 210/297 [00:10<00:03, 22.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 BoxB4, 9 BoxB8s, 31.8ms\n",
      "Speed: 3.7ms preprocess, 31.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BoxB4, 9 BoxB8s, 33.1ms\n",
      "Speed: 0.9ms preprocess, 33.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BoxB4, 10 BoxB8s, 29.1ms\n",
      "Speed: 4.2ms preprocess, 29.1ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  72%|███████▏  | 213/297 [00:10<00:03, 21.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 BoxB4, 11 BoxB8s, 31.2ms\n",
      "Speed: 3.8ms preprocess, 31.2ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 12 BoxB8s, 33.2ms\n",
      "Speed: 1.5ms preprocess, 33.2ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 14 BoxB8s, 32.2ms\n",
      "Speed: 4.1ms preprocess, 32.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  73%|███████▎  | 216/297 [00:10<00:03, 21.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 BoxB4, 12 BoxB8s, 30.9ms\n",
      "Speed: 4.2ms preprocess, 30.9ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BoxB4, 12 BoxB8s, 33.0ms\n",
      "Speed: 0.3ms preprocess, 33.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 13 BoxB8s, 41.8ms\n",
      "Speed: 0.0ms preprocess, 41.8ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  74%|███████▎  | 219/297 [00:10<00:03, 21.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 11 BoxB8s, 33.4ms\n",
      "Speed: 0.0ms preprocess, 33.4ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 12 BoxB8s, 29.7ms\n",
      "Speed: 4.1ms preprocess, 29.7ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BoxB4, 12 BoxB8s, 31.5ms\n",
      "Speed: 4.3ms preprocess, 31.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  75%|███████▍  | 222/297 [00:10<00:03, 22.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 12 BoxB8s, 31.9ms\n",
      "Speed: 4.3ms preprocess, 31.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box4G, 9 BoxB8s, 32.8ms\n",
      "Speed: 4.3ms preprocess, 32.8ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Box4Gs, 12 BoxB8s, 34.0ms\n",
      "Speed: 0.0ms preprocess, 34.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  76%|███████▌  | 225/297 [00:11<00:03, 21.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 Box4Gs, 12 BoxB8s, 31.9ms\n",
      "Speed: 4.1ms preprocess, 31.9ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Box4Gs, 3 BoxB4s, 11 BoxB8s, 30.4ms\n",
      "Speed: 3.0ms preprocess, 30.4ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box4G, 1 BoxB4, 12 BoxB8s, 37.6ms\n",
      "Speed: 0.0ms preprocess, 37.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  77%|███████▋  | 228/297 [00:11<00:03, 21.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 3 Box4Gs, 3 BoxB4s, 11 BoxB8s, 33.0ms\n",
      "Speed: 1.1ms preprocess, 33.0ms inference, 6.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 Box4Gs, 3 BoxB4s, 11 BoxB8s, 31.9ms\n",
      "Speed: 0.5ms preprocess, 31.9ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Box4Gs, 12 BoxB8s, 36.5ms\n",
      "Speed: 0.0ms preprocess, 36.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  78%|███████▊  | 231/297 [00:11<00:02, 22.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 Box4Gs, 3 BoxB4s, 12 BoxB8s, 42.8ms\n",
      "Speed: 0.0ms preprocess, 42.8ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Box4Gs, 4 BoxB4s, 10 BoxB8s, 27.9ms\n",
      "Speed: 4.2ms preprocess, 27.9ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Box4Gs, 3 BoxB4s, 13 BoxB8s, 32.2ms\n",
      "Speed: 3.7ms preprocess, 32.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  79%|███████▉  | 234/297 [00:11<00:02, 21.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 3 Box4Gs, 4 BoxB4s, 11 BoxB8s, 32.2ms\n",
      "Speed: 4.3ms preprocess, 32.2ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Box4Gs, 3 BoxB4s, 11 BoxB8s, 32.7ms\n",
      "Speed: 1.8ms preprocess, 32.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Box4Gs, 4 BoxB4s, 10 BoxB8s, 31.7ms\n",
      "Speed: 4.0ms preprocess, 31.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  80%|███████▉  | 237/297 [00:11<00:02, 21.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 3 Box4Gs, 4 BoxB4s, 12 BoxB8s, 40.4ms\n",
      "Speed: 0.0ms preprocess, 40.4ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Box4Gs, 1 BoxB4, 13 BoxB8s, 31.5ms\n",
      "Speed: 3.0ms preprocess, 31.5ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Box4Gs, 3 BoxB4s, 11 BoxB8s, 31.5ms\n",
      "Speed: 4.4ms preprocess, 31.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  81%|████████  | 240/297 [00:11<00:02, 21.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 3 Box4Gs, 1 Box8G, 4 BoxB4s, 12 BoxB8s, 36.2ms\n",
      "Speed: 0.0ms preprocess, 36.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Box4Gs, 4 BoxB4s, 11 BoxB8s, 30.9ms\n",
      "Speed: 3.0ms preprocess, 30.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Box4Gs, 1 Box8G, 4 BoxB4s, 11 BoxB8s, 31.2ms\n",
      "Speed: 4.1ms preprocess, 31.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  82%|████████▏ | 243/297 [00:11<00:02, 21.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 Box4Gs, 1 Box8G, 3 BoxB4s, 12 BoxB8s, 31.8ms\n",
      "Speed: 4.2ms preprocess, 31.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Box4Gs, 4 Box8Gs, 4 BoxB4s, 10 BoxB8s, 30.2ms\n",
      "Speed: 3.9ms preprocess, 30.2ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Box4Gs, 5 Box8Gs, 4 BoxB4s, 10 BoxB8s, 31.6ms\n",
      "Speed: 4.3ms preprocess, 31.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  83%|████████▎ | 246/297 [00:12<00:02, 21.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 Box4Gs, 2 Box8Gs, 4 BoxB4s, 10 BoxB8s, 40.1ms\n",
      "Speed: 0.0ms preprocess, 40.1ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Box4Gs, 5 Box8Gs, 4 BoxB4s, 10 BoxB8s, 31.6ms\n",
      "Speed: 3.1ms preprocess, 31.6ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Box4Gs, 4 Box8Gs, 4 BoxB4s, 10 BoxB8s, 33.3ms\n",
      "Speed: 0.0ms preprocess, 33.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  84%|████████▍ | 249/297 [00:12<00:02, 21.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 3 Box4Gs, 7 Box8Gs, 3 BoxB4s, 10 BoxB8s, 33.8ms\n",
      "Speed: 0.5ms preprocess, 33.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Box4Gs, 7 Box8Gs, 4 BoxB4s, 11 BoxB8s, 28.8ms\n",
      "Speed: 2.9ms preprocess, 28.8ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Box4Gs, 7 Box8Gs, 4 BoxB4s, 10 BoxB8s, 33.3ms\n",
      "Speed: 0.0ms preprocess, 33.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  85%|████████▍ | 252/297 [00:12<00:02, 21.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 Box4Gs, 4 Box8Gs, 5 BoxB4s, 10 BoxB8s, 35.1ms\n",
      "Speed: 0.0ms preprocess, 35.1ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box4G, 6 Box8Gs, 5 BoxB4s, 9 BoxB8s, 29.9ms\n",
      "Speed: 3.2ms preprocess, 29.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Box4Gs, 6 Box8Gs, 5 BoxB4s, 12 BoxB8s, 32.7ms\n",
      "Speed: 0.0ms preprocess, 32.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  86%|████████▌ | 255/297 [00:12<00:01, 21.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 Box4G, 7 Box8Gs, 5 BoxB4s, 12 BoxB8s, 33.0ms\n",
      "Speed: 4.2ms preprocess, 33.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 7 Box8Gs, 4 BoxB4s, 10 BoxB8s, 31.2ms\n",
      "Speed: 5.6ms preprocess, 31.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box4G, 6 Box8Gs, 5 BoxB4s, 11 BoxB8s, 31.6ms\n",
      "Speed: 4.5ms preprocess, 31.6ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  87%|████████▋ | 258/297 [00:12<00:01, 21.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 Box4G, 8 Box8Gs, 5 BoxB4s, 11 BoxB8s, 32.4ms\n",
      "Speed: 3.7ms preprocess, 32.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box4G, 7 Box8Gs, 5 BoxB4s, 11 BoxB8s, 30.7ms\n",
      "Speed: 3.0ms preprocess, 30.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box4G, 7 Box8Gs, 4 BoxB4s, 11 BoxB8s, 32.7ms\n",
      "Speed: 4.3ms preprocess, 32.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  88%|████████▊ | 261/297 [00:12<00:01, 21.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 Box4G, 10 Box8Gs, 5 BoxB4s, 9 BoxB8s, 33.1ms\n",
      "Speed: 0.4ms preprocess, 33.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box4G, 9 Box8Gs, 4 BoxB4s, 9 BoxB8s, 31.0ms\n",
      "Speed: 3.0ms preprocess, 31.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box4G, 9 Box8Gs, 4 BoxB4s, 9 BoxB8s, 30.6ms\n",
      "Speed: 4.4ms preprocess, 30.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  89%|████████▉ | 264/297 [00:12<00:01, 21.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 Box4Gs, 8 Box8Gs, 4 BoxB4s, 8 BoxB8s, 42.1ms\n",
      "Speed: 0.0ms preprocess, 42.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Box4Gs, 9 Box8Gs, 4 BoxB4s, 8 BoxB8s, 31.7ms\n",
      "Speed: 2.9ms preprocess, 31.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 Box8Gs, 5 BoxB4s, 8 BoxB8s, 31.8ms\n",
      "Speed: 4.1ms preprocess, 31.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  90%|████████▉ | 267/297 [00:13<00:01, 21.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 7 Box8Gs, 5 BoxB4s, 8 BoxB8s, 30.2ms\n",
      "Speed: 4.7ms preprocess, 30.2ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Box4Gs, 5 Box8Gs, 5 BoxB4s, 10 BoxB8s, 32.4ms\n",
      "Speed: 3.3ms preprocess, 32.4ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Box8Gs, 4 BoxB4s, 9 BoxB8s, 33.7ms\n",
      "Speed: 0.0ms preprocess, 33.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  91%|█████████ | 270/297 [00:13<00:01, 21.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 Box4G, 3 Box8Gs, 5 BoxB4s, 8 BoxB8s, 33.0ms\n",
      "Speed: 0.0ms preprocess, 33.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Box4Gs, 5 BoxB4s, 8 BoxB8s, 33.8ms\n",
      "Speed: 0.0ms preprocess, 33.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box4G, 4 BoxB4s, 8 BoxB8s, 33.1ms\n",
      "Speed: 4.3ms preprocess, 33.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  92%|█████████▏| 273/297 [00:13<00:01, 21.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 Box4G, 3 Box8Gs, 3 BoxB4s, 8 BoxB8s, 32.9ms\n",
      "Speed: 4.2ms preprocess, 32.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box4G, 4 BoxB4s, 9 BoxB8s, 31.9ms\n",
      "Speed: 2.3ms preprocess, 31.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box4G, 4 BoxB4s, 8 BoxB8s, 30.5ms\n",
      "Speed: 6.5ms preprocess, 30.5ms inference, 7.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  93%|█████████▎| 276/297 [00:13<00:00, 21.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 Box4G, 4 BoxB4s, 8 BoxB8s, 32.9ms\n",
      "Speed: 4.3ms preprocess, 32.9ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 BoxB4s, 8 BoxB8s, 29.3ms\n",
      "Speed: 2.8ms preprocess, 29.3ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 BoxB4s, 8 BoxB8s, 32.9ms\n",
      "Speed: 4.3ms preprocess, 32.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  94%|█████████▍| 279/297 [00:13<00:00, 21.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 BoxB4s, 9 BoxB8s, 32.0ms\n",
      "Speed: 4.3ms preprocess, 32.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 BoxB4s, 9 BoxB8s, 30.3ms\n",
      "Speed: 3.1ms preprocess, 30.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box8G, 4 BoxB4s, 9 BoxB8s, 31.1ms\n",
      "Speed: 3.7ms preprocess, 31.1ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  95%|█████████▍| 282/297 [00:13<00:00, 21.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 BoxB4s, 7 BoxB8s, 31.2ms\n",
      "Speed: 3.2ms preprocess, 31.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 BoxB4s, 8 BoxB8s, 32.9ms\n",
      "Speed: 1.9ms preprocess, 32.9ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box4G, 4 BoxB4s, 6 BoxB8s, 41.4ms\n",
      "Speed: 0.0ms preprocess, 41.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  96%|█████████▌| 285/297 [00:13<00:00, 21.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 Box4G, 4 BoxB4s, 7 BoxB8s, 30.6ms\n",
      "Speed: 2.7ms preprocess, 30.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box4G, 1 Box8G, 4 BoxB4s, 5 BoxB8s, 31.6ms\n",
      "Speed: 2.0ms preprocess, 31.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box4G, 4 BoxB4s, 7 BoxB8s, 32.9ms\n",
      "Speed: 4.1ms preprocess, 32.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  97%|█████████▋| 288/297 [00:14<00:00, 21.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 Box4G, 1 Box8G, 4 BoxB4s, 7 BoxB8s, 31.1ms\n",
      "Speed: 3.3ms preprocess, 31.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box4G, 1 Box8G, 4 BoxB4s, 4 BoxB8s, 30.8ms\n",
      "Speed: 3.5ms preprocess, 30.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box4G, 4 BoxB4s, 3 BoxB8s, 28.9ms\n",
      "Speed: 4.6ms preprocess, 28.9ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  98%|█████████▊| 291/297 [00:14<00:00, 21.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 Box4G, 5 BoxB4s, 2 BoxB8s, 31.5ms\n",
      "Speed: 2.9ms preprocess, 31.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box4G, 4 BoxB4s, 3 BoxB8s, 30.6ms\n",
      "Speed: 4.3ms preprocess, 30.6ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box4G, 4 BoxB4s, 3 BoxB8s, 32.7ms\n",
      "Speed: 4.0ms preprocess, 32.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  99%|█████████▉| 294/297 [00:14<00:00, 21.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 Box4G, 4 BoxB4s, 3 BoxB8s, 33.1ms\n",
      "Speed: 4.0ms preprocess, 33.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Box8G, 4 BoxB4s, 1 BoxB8, 31.6ms\n",
      "Speed: 2.0ms preprocess, 31.6ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Box8Gs, 3 BoxB4s, 3 BoxB8s, 32.9ms\n",
      "Speed: 0.5ms preprocess, 32.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 297/297 [00:14<00:00, 20.51it/s]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "video_path = r\"C:\\Users\\nicol\\Documents\\GitHub\\sew\\YOLO\\output_good2\\output_001.mp4\"\n",
    "output_video_path = \"output.mp4\"\n",
    "model = YOLO(\"bestv8l.pt\")\n",
    "render_video(video_path, output_video_path, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
