{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook servant à faire l'augmentation du jeu de données de segmentation et faire le détourage des rangées si souhaité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import albumentations as A\n",
    "\n",
    "import json\n",
    "import yaml\n",
    "\n",
    "from glob import glob\n",
    "from re import sub\n",
    "from random import randrange\n",
    "import os\n",
    "from PIL import Image\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import numpy as np\n",
    "import supervision as sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation des chemins utilisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect = False # Si True affiche les toutes les images augmentées (lent)\n",
    "do_cut_out = False # Si True créer in dossier avec les images détourées\n",
    "\n",
    "name = 'S2_6' # Nom pour les dossier finaux (detection_dataset_<name> et cut_out_dataset_<name>)\n",
    "\n",
    "'''\n",
    "num_aug: int\n",
    "Le nombre d'images crée par la première transformation pour chaque image source\n",
    "Attention, il y a une étape qui fait l'image miroir de toutes les images\n",
    "Au final on a (nb_img_src * (num_aug + 1)) * 2 images dans le dossier de sortie\n",
    "'''\n",
    "num_aug = 6\n",
    "\n",
    "'''\n",
    "src_dir: str\n",
    "Dossier source avec sous dossiers \"images\" et \"labels\" et fichier notes.json\n",
    "'''\n",
    "src_dir = \"source\"\n",
    "\n",
    "'''\n",
    "seg_res_path: str\n",
    "Dossier de sortie\n",
    "\n",
    "seg_res_path\n",
    "|- train\n",
    "|   |- images\n",
    "|   |   |- img1.jpg\n",
    "|   |   |- img2.jpg\n",
    "|   |   |- ...\n",
    "|   |- labels\n",
    "|       |- img1.txt\n",
    "|       |- img2.txt\n",
    "|       |- ...\n",
    "|- val\n",
    "|   |- images\n",
    "|   |   |- img1.jpg\n",
    "|   |   |- img2.jpg\n",
    "|   |   |- ...\n",
    "|   |- labels\n",
    "|       |- img1.txt\n",
    "|       |- img2.txt\n",
    "|       |- ...\n",
    "|- test\n",
    "|   |- ...\n",
    "|- data.yaml\n",
    "'''\n",
    "seg_res_path = \"segmentation_dataset_\" + name\n",
    "\n",
    "cut_out_res_path = \"cut_out_dataset_\" + name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions de visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOX_COLOR = (255, 0, 0) # Red\n",
    "TEXT_COLOR = (255, 255, 255) # White\n",
    "\n",
    "\n",
    "def visualize_bbox(img, bbox, color=BOX_COLOR, thickness=2):\n",
    "    \"\"\"Ajoute le boite encadrante à l'image\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Image source\n",
    "        bbox (list: int(x_min, y_min, x_max, y_max)): Coordonnées de la boite encadrante\n",
    "        color (tuple: int, optional): Couleur de la boite. Defaults to BOX_COLOR.\n",
    "        thickness (int, optional): Epaisseur de la boite. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Image avec la boite encadrante\n",
    "    \"\"\"\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)\n",
    "    return img\n",
    "\n",
    "def visualize_mask(img, mask):\n",
    "    \"\"\"Ajoute le mask à l'image\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Image source\n",
    "        mask (np.ndarray): Mask à visualiser\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Image avec le mask\n",
    "    \"\"\"\n",
    "    color = np.array([0,255,0], dtype='uint8')\n",
    "    masked_img = np.where(mask[...,None], color, img) # image avec mask plein\n",
    "    img = cv2.addWeighted(img, 0.8, masked_img, 0.2,0) # image avec mask dilué\n",
    "    return img\n",
    "\n",
    "def visualize(image, masks, bboxes, ax = None):\n",
    "    \"\"\"Affiche l'image avec ses masks et boites encadrantes\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): Image source\n",
    "        masks (list: np.ndarray): Masks à visualiser\n",
    "        bboxes (list: list): Coordonnées des boites encadrantes\n",
    "        ax (plt.axes, optional): Position dans la figure matplotlib. Defaults to None.\n",
    "    \"\"\"\n",
    "    img = image.copy()\n",
    "    for mask in masks:\n",
    "        img = visualize_mask(img, mask)\n",
    "    for bbox in bboxes:\n",
    "        img = visualize_bbox(img, bbox)\n",
    "    if ax != None:\n",
    "        ax.imshow(img)\n",
    "    else:\n",
    "        plt.figure(figsize=(12, 12))\n",
    "        #plt.axis('off')\n",
    "        plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation\n",
    "\n",
    "Penser à modifier le chemin d'accès au données source si changements\n",
    "\n",
    "L'augmentation est faite en 2 étapes, une première avec des augmentation non systématiques (c'est à dire qu'elles ont des probabilité de ne pas ce produire) et une deuxième étape avec des augmentation systématiques (miroir entre autre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise en place du dossier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création des dossier et sous dossiers\n",
    "splits = []\n",
    "for split in ['test', 'val', 'train']:\n",
    "    if split in os.listdir(src_dir):\n",
    "        splits .append(split)\n",
    "\n",
    "try:\n",
    "    os.mkdir(seg_res_path)\n",
    "except OSError as error:  \n",
    "    print(error)\n",
    "for split in splits:\n",
    "    try:\n",
    "        os.mkdir(os.path.join(seg_res_path, split))\n",
    "    except OSError as error:  \n",
    "        print(error)\n",
    "    try:\n",
    "        os.mkdir(os.path.join(seg_res_path, split, 'images'))\n",
    "    except OSError as error:  \n",
    "        print(error)\n",
    "    try:\n",
    "        os.mkdir(os.path.join(seg_res_path, split, 'labels'))\n",
    "    except OSError as error:  \n",
    "        print(error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copie des données val et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = []\n",
    "for split in ['test', 'val']:\n",
    "    if split in os.listdir(src_dir):\n",
    "        splits .append(split)\n",
    "        \n",
    "\n",
    "for split in splits:\n",
    "    for kind in ['images', 'labels']:\n",
    "        src_path = os.path.join(src_dir, split, kind)\n",
    "        targ_path = os.path.join(seg_res_path, split, kind)\n",
    "        for file in tqdm(os.listdir(src_path), desc = 'file copied'):\n",
    "            shutil.copy2(os.path.join(src_path, file), targ_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du fichier .yaml pour YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "try:\n",
    "    json_f = open(os.path.join(src_dir,'train', \"notes.json\"))\n",
    "    json_data = json.load(json_f)\n",
    "\n",
    "    yaml_f = open(os.path.join(seg_res_path, \"data.yaml\"), 'w')\n",
    "    names = {}\n",
    "\n",
    "    # cat2name sert à lier l'indice de la classe à son nom\n",
    "    k = 0\n",
    "    cat2name = [0] * len(json_data['categories'])\n",
    "    for category in json_data['categories']:\n",
    "        names[category['id']] = category['name']\n",
    "        cat2name[k] = category['name']\n",
    "        k += 1\n",
    "    \n",
    "    # ajout des champs de données\n",
    "    data['names'] = names\n",
    "    data['nc'] = len(json_data['categories'])\n",
    "    data['train'] =\"./train/images\"\n",
    "    data['val'] = \"./val/images\"\n",
    "    data['test'] = \"./test/images\"\n",
    "\n",
    "    # écriture dans le fichier yaml\n",
    "    yaml.dump(data, yaml_f, default_flow_style=False, allow_unicode=True)\n",
    "\n",
    "    # fermeture des fichiers\n",
    "    json_f.close()\n",
    "    yaml_f.close()\n",
    "\n",
    "except IOError as error:\n",
    "    print(error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des données augmentées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dossier cibles\n",
    "img_src_path = os.path.join(src_dir, 'train', 'images')\n",
    "lab_src_path = os.path.join(src_dir, 'train', 'labels')\n",
    "img_seg_res_path = os.path.join(seg_res_path, 'train', 'images')\n",
    "lab_seg_res_path = os.path.join(seg_res_path, 'train', 'labels')\n",
    "images = glob('*.jpg', dir_fd=img_src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformations\n",
    "transform1 = A.Compose(\n",
    "    [\n",
    "        # Pixels\n",
    "        A.RandomBrightnessContrast(p=0.2),\n",
    "        A.RandomGamma(p=0.2),\n",
    "        A.ISONoise(p=0.2),\n",
    "        A.GaussNoise(p=0.2),\n",
    "        A.CLAHE(p=0.2), # add contrast\n",
    "        A.RandomSunFlare(src_radius = 100, num_flare_circles_upper= 10, p=0.2), # attention au rayon, si trop grand peut entièrement caché une boite\n",
    "        A.RandomSunFlare(src_radius = 100, num_flare_circles_upper= 10, p=0.2),\n",
    "        A.RandomSunFlare(src_radius = 100, num_flare_circles_upper= 10, p=0.2), # plusieur pour avoir different angles (ils se forment en ligne)\n",
    "        \n",
    "        # Spatial\n",
    "        A.Rotate(limit=(-10, 10), p=0.3), # voir quel angles sont raisonnables\n",
    "        A.PixelDropout(dropout_prob=0.01 ,p=0.5),\n",
    "    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['category_ids']), #dans BbowParams on peut ajouter des paramètres de tailles... utile pour les boites qui deviendraient trop petites\n",
    ")\n",
    "\n",
    "transform2 = A.Compose(\n",
    "    [\n",
    "        A.HorizontalFlip(p=1),\n",
    "    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['category_ids']), #dans BbowParams on peut ajouter des paramètres de tailles... utile pour les boites qui deviendraient trop petites\n",
    ")\n",
    "\n",
    "for img_name in tqdm(images, desc = 'images processed'):\n",
    "    '''\n",
    "    Lecture des fichiers sources avec récupération des boîtes englobantes\n",
    "    '''\n",
    "    image = cv2.imread(os.path.join(img_src_path, img_name)) # lire l'image\n",
    "    h, w, _ = image.shape\n",
    "    category_ids = []\n",
    "    label_name = sub(\"jpg$\", \"txt\", img_name)\n",
    "    with open(os.path.join(lab_src_path, label_name), \"r\") as label_file:\n",
    "        lines = label_file.readlines()\n",
    "        polygons = np.empty(len(lines), dtype = object) # Array des polygones des rangées de la figure\n",
    "        for line_id in range(len(lines)): # Pour chaque annotation (rangée)\n",
    "            split_line = lines[line_id].split(' ')\n",
    "            category_ids.append(int(split_line[0]))\n",
    "            split_line = list(map(float, split_line))\n",
    "            polygon = np.empty(shape=(len(split_line)//2,2), dtype=np.int32) # Array des sommet du polygon de la rangée\n",
    "            for i in range(1, len(split_line), 2):\n",
    "                polygon[i//2] = [split_line[i]*w, split_line[i+1]*h]\n",
    "            polygons[line_id] = polygon\n",
    "\n",
    "    masks = [ sv.polygon_to_mask(p,(w,h)) for p in polygons] # Conversion des polygons en masks\n",
    "    masks = np.array(masks)\n",
    "    bboxes = [ sv.polygon_to_xyxy(p) for p in polygons] # Conversion des polygons pour avoir la boite encadrante la plus proche\n",
    "\n",
    "    # copie\n",
    "    shutil.copy2(os.path.join(img_src_path, img_name), img_seg_res_path)\n",
    "    shutil.copy2(os.path.join(lab_src_path, label_name), lab_seg_res_path)\n",
    "\n",
    "    for ind in range(num_aug):\n",
    "        transformed = transform1(image=image, masks=masks, bboxes=bboxes, category_ids=category_ids)\n",
    "        transformed_mirror = transform2(image=transformed['image'], masks=transformed['masks'], bboxes=transformed['bboxes'], category_ids=transformed['category_ids'])\n",
    "\n",
    "        cv2.imwrite(os.path.join(img_seg_res_path, \"transformed_\" + str(ind) + \"_\" + img_name), transformed['image'])\n",
    "        new_label_file = open(os.path.join(lab_seg_res_path, \"transformed_\" + str(ind) + \"_\" + label_name), 'w')\n",
    "        polygons = [ sv.mask_to_polygons(m) for m in transformed['masks'] ]\n",
    "        for line in range(len(polygons)):\n",
    "            new_label_file.write(str(transformed['category_ids'][line]))\n",
    "            for vertice in polygons[line][0]:\n",
    "                new_label_file.write(\" \" + str(vertice[0]/w) + \" \" + str(vertice[1]/h))\n",
    "            new_label_file.write('\\n')\n",
    "        new_label_file.close()\n",
    "\n",
    "        cv2.imwrite(os.path.join(img_seg_res_path, \"transformed_mirror_\" + str(ind) + \"_\" + img_name), transformed_mirror['image'])\n",
    "        new_label_file = open(os.path.join(lab_seg_res_path, \"transformed_mirror_\" + str(ind) + \"_\" + label_name), 'w')\n",
    "        polygons = [ sv.mask_to_polygons(m) for m in transformed_mirror['masks'] ]\n",
    "        for line in range(len(polygons)):\n",
    "            new_label_file.write(str(transformed_mirror['category_ids'][line]))\n",
    "            for vertice in polygons[line][0]:\n",
    "                new_label_file.write(\" \" + str(vertice[0]/w) + \" \" + str(vertice[1]/h))\n",
    "            new_label_file.write('\\n')\n",
    "        new_label_file.close()\n",
    "\n",
    "    mirror = transform2(image=image, masks=masks, bboxes=bboxes, category_ids=category_ids)\n",
    "    cv2.imwrite(os.path.join(img_seg_res_path, \"mirror_\" + img_name), mirror['image'])\n",
    "    new_label_file = open(os.path.join(lab_seg_res_path, \"mirror_\" + label_name), 'w')\n",
    "    polygons = [ sv.mask_to_polygons(m) for m in mirror['masks'] ]\n",
    "    for line in range(len(polygons)):\n",
    "        new_label_file.write(str(mirror['category_ids'][line]))\n",
    "        for vertice in polygons[line][0]:\n",
    "            new_label_file.write(\" \" + str(vertice[0]/w) + \" \" + str(vertice[1]/h))\n",
    "        new_label_file.write('\\n')\n",
    "    new_label_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data augmentation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if inspect:    \n",
    "    images = glob('*.jpg', dir_fd=img_seg_res_path)\n",
    "    num_images = len(images)\n",
    "\n",
    "    num_grids = math.ceil(num_images / 9)\n",
    "    for grid in tqdm(range(num_grids), desc = 'grid'):\n",
    "        fig, axs = plt.subplots(3, 3, figsize=(20, 20))  # Create a 3x3 grid of subplots\n",
    "        grid_image_paths = images[grid * 9 : (grid + 1) * 9]\n",
    "\n",
    "\n",
    "        for ax, img_name in zip(axs.flatten(), grid_image_paths):\n",
    "            image = cv2.imread(img_seg_res_path + '/' + img_name)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            h, w, _ = image.shape\n",
    "            category_ids = []\n",
    "            label_name = sub(\"jpg$\", \"txt\", img_name)\n",
    "            with open(os.path.join(lab_seg_res_path, label_name), \"r\") as label_file:\n",
    "                lines = label_file.readlines()\n",
    "                polygons = np.empty(len(lines), dtype = object) # Array des polygones des rangées de la figure\n",
    "                for line_id in range(len(lines)): # Pour chaque annotation (rangée)\n",
    "                    split_line = lines[line_id].split(' ')\n",
    "                    category_ids.append(int(split_line[0]))\n",
    "                    split_line = list(map(float, split_line))\n",
    "                    polygon = np.empty(shape=(len(split_line)//2,2), dtype=np.int32) # Array des sommet du polygon de la rangée\n",
    "                    for i in range(1, len(split_line), 2):\n",
    "                        polygon[i//2] = [split_line[i]*w, split_line[i+1]*h]\n",
    "                    polygons[line_id] = polygon\n",
    "            masks = [ sv.polygon_to_mask(p,(w,h)) for p in polygons ] # Conversion des polygons en masks\n",
    "            masks = np.array(masks)\n",
    "            bboxes = [ sv.polygon_to_xyxy(p) for p in polygons] # Conversion des polygons pour avoir la boite encadrante la plus proche\n",
    "            visualize(image, masks, bboxes, ax)\n",
    "            ax.set_title(img_name)\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels_src = glob('*.txt', dir_fd=lab_src_path)\n",
    "labels_augment = glob('*.txt', dir_fd=lab_seg_res_path)\n",
    "img_src = glob('*.jpg', dir_fd=img_src_path)\n",
    "img_augment = glob('*.jpg', dir_fd=img_seg_res_path)\n",
    "\n",
    "# info source\n",
    "print(\"Il y a \" + str(len(labels_src)) + \" images dans le dossier source:\")\n",
    "\n",
    "label_count = [0] * len(cat2name)\n",
    "\n",
    "for fname in labels_src:\n",
    "    with open(lab_src_path + '/' + fname, \"r\") as label_file:\n",
    "        for line in label_file:\n",
    "            split_line = line.split(' ')\n",
    "            label_count[int(split_line[0])] += 1\n",
    "\n",
    "for i in range(len(cat2name)):\n",
    "    print(cat2name[i], \" a \", label_count[i], \" instances\")\n",
    "\n",
    "# info augmenté\n",
    "print(\"------------------------------------------\\nIl y a \" + str(len(labels_augment)) + \" images dans le dossier augmenté:\")\n",
    "\n",
    "label_count = [0] * len(cat2name)\n",
    "\n",
    "for fname in labels_augment:\n",
    "    with open(lab_seg_res_path + '/' + fname, \"r\") as label_file:\n",
    "        for line in label_file:\n",
    "            split_line = line.split(' ')\n",
    "            label_count[int(split_line[0])] += 1\n",
    "\n",
    "for i in range(len(cat2name)):\n",
    "    print(cat2name[i], \" a \", label_count[i], \" instances\")\n",
    "\n",
    "# info dimension moyenne images\n",
    "print(\"------------------------------------------\\nLes dimension moyennes du jeu source sont:\")\n",
    "mean_w = 0\n",
    "mean_h = 0\n",
    "\n",
    "for fname in img_src:\n",
    "    with Image.open(img_src_path + '/' + fname) as img:\n",
    "        w, h = img.size\n",
    "        mean_w += w\n",
    "        mean_h += h\n",
    "mean_w /= len(img_src)\n",
    "mean_h /= len(img_src)\n",
    "\n",
    "print(\"mean width = \", mean_w)\n",
    "print(\"mean heigh = \", mean_h)\n",
    "\n",
    "print(\"------------------------------------------\\nLes dimension moyennes du jeu augmenté sont:\")\n",
    "mean_w = 0\n",
    "mean_h = 0\n",
    "\n",
    "for fname in img_augment:\n",
    "    with Image.open(img_seg_res_path + '/' + fname) as img:\n",
    "        w, h = img.size\n",
    "        mean_w += w\n",
    "        mean_h += h\n",
    "mean_w /= len(img_augment)\n",
    "mean_h /= len(img_augment)\n",
    "\n",
    "print(\"mean width = \", mean_w)\n",
    "print(\"mean heigh = \", mean_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cut Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(do_cut_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_out(mask, img, bbox):\n",
    "    \"\"\"Détoure le mask de l'image et comble la boîte de pixels noirs\n",
    "\n",
    "    Args:\n",
    "        mask (np.ndarray): mask composé de 1 et 0 définissant les pixels à détourer\n",
    "        img (np.ndarray): image de référence\n",
    "        bbox (list): liste de 4 coordonnées définissant la boite encadrante\n",
    "\n",
    "    Returns:\n",
    "        np.array: image de la rangée détourée\n",
    "    \"\"\"\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    color = np.array([0,0,0], dtype='uint8')\n",
    "    cut_out_img = np.where(mask[...,None], img, color) # met les pixels correpsondans au 0 du mask en noir\n",
    "    cut_out_img = cut_out_img[y_min:y_max, x_min:x_max] # coupe l'image au dimensions de la boite encadrante\n",
    "    return cut_out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création des dossier et sous dossiers\n",
    "splits = []\n",
    "for split in ['test', 'val', 'train']:\n",
    "    if split in os.listdir(src_dir):\n",
    "        splits .append(split)\n",
    "\n",
    "try:\n",
    "    os.mkdir(cut_out_res_path)\n",
    "except OSError as error:  \n",
    "    print(error)\n",
    "for split in splits:\n",
    "    try:\n",
    "        os.mkdir(os.path.join(cut_out_res_path, split))\n",
    "    except OSError as error:  \n",
    "        print(error)\n",
    "    try:\n",
    "        os.mkdir(os.path.join(cut_out_res_path, split, 'images'))\n",
    "    except OSError as error:  \n",
    "        print(error)\n",
    "    try:\n",
    "        os.mkdir(os.path.join(cut_out_res_path, split, 'labels'))\n",
    "    except OSError as error:  \n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in splits:\n",
    "    # dossier cibles\n",
    "    img_src_path = os.path.join(src_dir, split, 'images')\n",
    "    lab_src_path = os.path.join(src_dir, split, 'labels')\n",
    "    img_cut_out_res_path = os.path.join(cut_out_res_path, split, 'images')\n",
    "    lab_cut_out_res_path = os.path.join(cut_out_res_path, split, 'labels')\n",
    "    images = glob('*.jpg', dir_fd=img_src_path)\n",
    "    \n",
    "    for img_name in tqdm(images, desc = 'images processed: ' + split):\n",
    "        image = cv2.imread(os.path.join(img_src_path, img_name)) # lire l'image\n",
    "        h, w, _ = image.shape\n",
    "        category_ids = []\n",
    "        label_name = sub(\"jpg$\", \"txt\", img_name)\n",
    "        with open(os.path.join(lab_src_path, label_name), \"r\") as label_file:\n",
    "            lines = label_file.readlines()\n",
    "            polygons = np.empty(len(lines), dtype = object)\n",
    "            for line_id in range(len(lines)):\n",
    "                split_line = lines[line_id].split(' ')\n",
    "                category_ids.append(int(split_line[0]))\n",
    "                split_line = list(map(float, split_line))\n",
    "                polygon = np.empty(shape=(len(split_line)//2,2), dtype=np.int32)\n",
    "                for i in range(1, len(split_line), 2):\n",
    "                    polygon[i//2] = [split_line[i]*w, split_line[i+1]*h]\n",
    "                polygons[line_id] = polygon\n",
    "        masks = [ sv.polygon_to_mask(p,(w,h)) for p in polygons ]\n",
    "        masks = np.array(masks)\n",
    "        bboxes = [ sv.polygon_to_xyxy(p) for p in polygons]\n",
    "\n",
    "        # découpage et sauvegarde\n",
    "        for k in range(len(masks)):\n",
    "            cut_out_img = cut_out(masks[k], image, bboxes[k])\n",
    "            cv2.imwrite(os.path.join(img_cut_out_res_path, str(k) + '_' + img_name), cut_out_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
