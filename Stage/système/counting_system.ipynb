{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook servant à faire une inférence décomposée (détection, segmentation et regression) de deux images du même instant afin de compter le nombre de rolls de chaque catégorie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import numbers\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "%matplotlib inline\n",
    "import shutil\n",
    "from scipy.ndimage import label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_threshold = 0.07 # minimum confidence for detection predictions to keep\n",
    "seg_threshold = 0.8 # minimum confidence for segmentation predictions to keep\n",
    "overlap_threshold = 1 # maximum commun part beetween mask before being consedered overlaping\n",
    "iou = 0.5 # pour NMS detection\n",
    "margin_y, margin_x = 20 ,1 # min 1\n",
    "reg_imgsz =[224,224]\n",
    "save = True # Si True garde les resultats intermédiaires dans le dossier \"tmp\"\n",
    "visualize = False # si True garde les images intermédiares des models de detection et segmentation (AI explain) -> lent\n",
    "\n",
    "front = 'presentation/front.jpg'\n",
    "top = 'presentation/top.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a modifier celon le modèle de regression\n",
    "def gen_new_model(weights):\n",
    "    \"\"\"Génère un modèles de regression et charge les poids pré-entrainés\n",
    "\n",
    "    Args:\n",
    "        weights (torch.collections.OrderedDict): Poids du modèle\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: Modèle de regression\n",
    "    \"\"\"\n",
    "    model = models.resnet18()\n",
    "\n",
    "    #modification de la dernière couche\n",
    "    model.fc = nn.Sequential( \n",
    "        nn.Linear(512, 1024),\n",
    "        nn.BatchNorm1d(1024),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(1024, 1024),\n",
    "        nn.BatchNorm1d(1024),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(1024, 512),\n",
    "        nn.BatchNorm1d(512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, 1)\n",
    "    )\n",
    "    \n",
    "    \n",
    "    model.load_state_dict(weights)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mise en place des models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_model = YOLO(os.path.join('models', 'det.pt'))\n",
    "seg_model = YOLO(os.path.join('models', 'seg.pt'))\n",
    "reg_model = gen_new_model(torch.load(os.path.join('models', 'reg.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supprime le dossier temporaire\n",
    "try:\n",
    "    shutil.rmtree('tmp')\n",
    "except WindowsError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(mask1, mask2, threshold):\n",
    "    \"\"\"Détermine si deux masks se superposent\n",
    "\n",
    "    Args:\n",
    "        mask1 (np.ndarray): Un mask\n",
    "        mask2 (np.ndarray): Un mask\n",
    "        threshold (float): Seuil de superposition toléré\n",
    "\n",
    "    Returns:\n",
    "        int:    - 0 si pas de superposition\n",
    "                - 1 si superposition et mask1 plus petit\n",
    "                - 2 si superposition et mask2 plus petit\n",
    "    \"\"\"\n",
    "    common = mask1*mask2\n",
    "    common_size = np.sum(common)\n",
    "    # trouver le plus petit mask\n",
    "    size1 = np.sum(mask1)\n",
    "    size2 = np.sum(mask2)\n",
    "    if size1 > size2:\n",
    "        smaller = 2\n",
    "        smaller_size = size2\n",
    "    else:\n",
    "        smaller = 1\n",
    "        smaller_size = size1\n",
    "    print(common_size/smaller_size)\n",
    "    if common_size/smaller_size > threshold:\n",
    "        return smaller # retourne le plus petit mask qui devra être supprimé\n",
    "    return 0 # pas d'overlap significatif\n",
    "\n",
    "def remove_overlap(seg_x_s, seg_conf_s, seg_xyxy_s, seg_mask_s, threshold):\n",
    "    \"\"\"Supprime les masks superposés\n",
    "\n",
    "    Args:\n",
    "        seg_x_s (list: int): Liste de coordonnées x des détections triées de gauche à droite (croissant)\n",
    "        seg_conf_s (list: float): Liste des scores de confiance des détections triés de gauche à droite (croissant)\n",
    "        seg_xyxy_s (list: list):  Liste des coordonnées des boites encadrantes des détections triés de gauche à droite (croissant)\n",
    "        seg_mask_s (list: np.ndarray):  Liste des masks des détections triés de gauche à droite (croissant)\n",
    "        threshold (float): Seuil de superposition toléré\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    while i != len(seg_mask_s):\n",
    "        j=i+1\n",
    "        while j != len(seg_mask_s):\n",
    "            overlapping_mask = overlap(seg_mask_s[i], seg_mask_s[j], threshold)\n",
    "            match overlapping_mask:\n",
    "                case 1: # supprimer le premier mask\n",
    "                    del(seg_x_s[i])\n",
    "                    del(seg_conf_s[i])\n",
    "                    del(seg_xyxy_s[i])\n",
    "                    del(seg_mask_s[i])\n",
    "                case 2: # supprimer le deuxième mask\n",
    "                    del(seg_x_s[j])\n",
    "                    del(seg_conf_s[j])\n",
    "                    del(seg_xyxy_s[j])\n",
    "                    del(seg_mask_s[j])\n",
    "                case 0:\n",
    "                    j+=1 # étape suivante (car pas de modification des listes)\n",
    "        i+=1\n",
    "    return seg_x_s, seg_conf_s, seg_xyxy_s, seg_mask_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padding(image, imgsz):\n",
    "    \"\"\"Ajoute des pixels noir pour avoir les bonnes dimensions d'image\n",
    "\n",
    "    Args:\n",
    "        image (PIL Image): Image source\n",
    "        imgsz (list: int(w, h)): Dimension cible\n",
    "\n",
    "    Returns:\n",
    "        list: Dimensions pour le rembourrage\n",
    "    \"\"\"\n",
    "    w, h = image.size\n",
    "    w_padding = max((imgsz[0] - w) / 2, 0)\n",
    "    h_padding = max((imgsz[1] - h) / 2, 0)\n",
    "    t_pad = h_padding if h_padding % 1 == 0 else h_padding+0.5\n",
    "    l_pad = w_padding if w_padding % 1 == 0 else w_padding+0.5\n",
    "    b_pad = h_padding if h_padding % 1 == 0 else h_padding-0.5\n",
    "    r_pad = w_padding if w_padding % 1 == 0 else w_padding-0.5\n",
    "    padding = (int(l_pad), int(t_pad), int(r_pad), int(b_pad))\n",
    "    return padding\n",
    "\n",
    "class NewPad(object):\n",
    "    def __init__(self, fill=0, padding_mode='constant', imgsz = [224,224]):\n",
    "        assert isinstance(fill, (numbers.Number, str, tuple))\n",
    "        assert padding_mode in ['constant', 'edge', 'reflect', 'symmetric']\n",
    "        self.imgsz = imgsz\n",
    "        self.fill = fill\n",
    "        self.padding_mode = padding_mode\n",
    "        \n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to be padded.\n",
    "\n",
    "        Returns:\n",
    "            PIL Image: Padded image.\n",
    "        \"\"\"\n",
    "        return F.pad(img, get_padding(img, self.imgsz), self.fill, self.padding_mode)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(padding={0}, fill={1}, padding_mode={2})'.\\\n",
    "            format(self.fill, self.padding_mode)\n",
    "    \n",
    "data_transforms = transforms.Compose([\n",
    "    NewPad(imgsz = reg_imgsz),\n",
    "    transforms.Resize((reg_imgsz[1], reg_imgsz[0])), # h,w\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_out(mask, img, bbox):\n",
    "    \"\"\"Détoure le mask de l'image\n",
    "\n",
    "    Args:\n",
    "        mask (np.ndarray): Mask à détourer\n",
    "        img (np.ndarray): Image source\n",
    "        bbox (list: int(x_min, y_min, x_max, y_max)): Boite encadrante\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Image détourée\n",
    "    \"\"\"\n",
    "    x_min, y_min, x_max, y_max = list(map(int, bbox))\n",
    "    mask = cv2.dilate(mask, np.ones((margin_y, margin_x), np.uint8)) # add margin around mask (for error resilience)\n",
    "    color = np.array([0,0,0], dtype='uint8')\n",
    "    cut_out_img = np.where(mask[...,None], img, color)\n",
    "    h, w, _ = cut_out_img.shape\n",
    "    cut_out_img = cut_out_img[max(y_min-margin_y, 0):min(y_max+margin_y,h), max(x_min-margin_x, 0):min(x_max+margin_x,w)]\n",
    "    return cut_out_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detectection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_result = det_model(front, cfg='cfg_det.yaml', visualize = visualize, conf = det_threshold, save = save, project='tmp', name = 'det', exist_ok=True, agnostic_nms=True, iou=iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_conf = [x for x in det_result[0].boxes.conf.tolist() if x > det_threshold]\n",
    "det_xyxy = [det_result[0].boxes.xyxy[i].tolist() for i in range(len(det_result[0].boxes.conf.tolist())) if det_result[0].boxes.conf[i] > det_threshold]\n",
    "det_x = [elmt[0] for elmt in det_xyxy]\n",
    "det_class = [det_model.names[det_result[0].boxes.cls[i].tolist()] for i in range(len(det_result[0].boxes.conf.tolist())) if det_result[0].boxes.conf[i] > det_threshold]\n",
    "\n",
    "det_x_s, det_conf_s, det_xyxy_s, det_class_s = map(list, zip(*sorted(zip(det_x, det_conf, det_xyxy, det_class)))) # tri des listes par rapport à det_x (position gauche/droite des boites prédites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_result = seg_model(top, cfg='cfg_seg.yaml', visualize = visualize, save = save, show_boxes = False, conf = seg_threshold, project='tmp', name = 'seg', exist_ok =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_conf = [x for x in seg_result[0].boxes.conf.tolist() if x > seg_threshold]\n",
    "seg_xyxy = [seg_result[0].boxes.xyxy[i].tolist() for i in range(len(seg_result[0].boxes.conf.tolist())) if seg_result[0].boxes.conf[i] > seg_threshold]\n",
    "seg_x = [elmt[0] for elmt in seg_xyxy]\n",
    "seg_mask = [seg_result[0].masks.data[i].cpu().numpy() for i in range(len(seg_result[0].boxes.conf.tolist())) if seg_result[0].boxes.conf[i] > seg_threshold]\n",
    "\n",
    "seg_x_s, seg_conf_s, seg_xyxy_s, seg_mask_s = map(list, zip(*sorted(zip(seg_x, seg_conf, seg_xyxy, seg_mask)))) # tri des listes par rapport à det_x (position gauche/droite des boites prédites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation de la segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_bbox(img, bbox, color=(255, 0, 0), thickness=2):\n",
    "    \"\"\"Ajoute le boite encadrante à l'image\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Image source\n",
    "        bbox (list: int(x_min, y_min, x_max, y_max)): Coordonnées de la boite encadrante\n",
    "        color (tuple: int, optional): Couleur de la boite. Defaults to (255, 0, 0).\n",
    "        thickness (int, optional): Epaisseur de la boite. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Image avec la boite encadrante\n",
    "    \"\"\"\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskVisualize(image, mask):\n",
    "    \"\"\"Ajoute le mask à l'image\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Image source\n",
    "        mask (np.ndarray): Mask à visualiser\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Image avec le mask\n",
    "    \"\"\"\n",
    "    color = np.array([255,0,0], dtype='uint8')\n",
    "    mask = cv2.dilate(mask, kernel = np.ones((margin_y, margin_x), np.uint8)) # déforme le mask pour prendre de la marge\n",
    "    masked_img = np.where(mask[...,None], color, image) # image avec mask plein\n",
    "    image = cv2.addWeighted(image, 0.8, masked_img, 0.2,0) # image avec mask dilué\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(top)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "w, h, _ = image.shape\n",
    "for i in range(len(seg_conf_s)):\n",
    "    image = maskVisualize(image, cv2.resize(seg_mask_s[i], (h,w), interpolation =cv2.INTER_LANCZOS4))# cv2.INTER_LINEAR))\n",
    "    #image = visualize_bbox(image, seg_xyxy_s[i])\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "if save:\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite('tmp/seg/overlap.jpg', image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mask in seg_mask_s:\n",
    "    print(mask.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Sépare les mask non continues\n",
    "\n",
    "Il faudra alors voir qu'est ce qui est gardé (sur cette image on a deux fois des segmentation qui prend les deux rangées mais qui se concentre sur chaque fois une des 2 (en entière) et l'autre est coupée)\n",
    "Sur une des autres images on avais un petit bout de mask non continu mais sans aucun sens...\n",
    "à priori si une segmentation a plusierus parties continues, un des partie est la vrai cible complete... et l'autre (plus petite) est à ignorer/supprimer, si l'autre est une autre rangée elle devrai être\n",
    "segmenter aussi (séparement)\n",
    "\"\"\"\n",
    "for id, mask in enumerate(seg_mask_s):\n",
    "    mask_copy= mask.copy()\n",
    "    labeled_array, num_features = label(mask_copy)\n",
    "    size_max = 0\n",
    "    for i in range(1, num_features+1):    \n",
    "        feature_mask = np.array(labeled_array, dtype='float32')\n",
    "        feature_mask[feature_mask!=i]=0 # cache les autres parties continues\n",
    "        feature_mask[feature_mask!=0]=1.0\n",
    "        size=feature_mask.sum()\n",
    "        print(feature_mask.dtype)\n",
    "        if size_max < size:\n",
    "            size_max=size\n",
    "            seg_mask_s[id]=feature_mask.copy()\n",
    "# marche sur cet exemple, à vérifier sur d'autre ou continuer avec le model \"triche\"\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_x_s, seg_conf_s, seg_xyxy_s, seg_mask_s = remove_overlap(seg_x_s, seg_conf_s, seg_xyxy_s, seg_mask_s, overlap_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(top)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "w, h, _ = image.shape\n",
    "for i in range(len(seg_conf_s)):\n",
    "    image = maskVisualize(image, cv2.resize(seg_mask_s[i], (h,w), interpolation =cv2.INTER_LANCZOS4))# cv2.INTER_LINEAR))\n",
    "    #image = visualize_bbox(image, seg_xyxy_s[i])\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "if save:\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite('tmp/seg/no_overlap.jpg', image)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cropping & regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# créer dossier temporaire\n",
    "try:\n",
    "    os.makedirs('tmp/cut_out')\n",
    "except OSError:\n",
    "    pass\n",
    "# préparer le model de regression\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "reg_model.to(device)\n",
    "reg_model.eval()\n",
    "reg_s = []\n",
    "# Découpages puis regressions\n",
    "image = cv2.imread(top)\n",
    "w, h, _ = image.shape\n",
    "for i in range(len(seg_conf_s)):\n",
    "    # cropping & save for debug\n",
    "    img = cut_out(cv2.resize(seg_mask_s[i], (h,w), interpolation = cv2.INTER_LINEAR), image, seg_xyxy_s[i])\n",
    "    cv2.imwrite(\"tmp/cut_out/{}.jpg\".format(i), img)\n",
    "    # regression\n",
    "    img = Image.open(\"tmp/cut_out/{}.jpg\".format(i)).convert(\"RGB\")\n",
    "    img = data_transforms(img)\n",
    "    if save:\n",
    "        transform = transforms.ToPILImage()\n",
    "        imgpil = transform(img)\n",
    "        imgpil.save(f'tmp/cut_out/transformed{i}.jpg')\n",
    "    img = torch.unsqueeze(img, dim=0)\n",
    "    img = img.to(device)\n",
    "    pred = reg_model(img)\n",
    "    pred = round(pred[0][0].item())\n",
    "    print(pred)\n",
    "    reg_s.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"reg_model = gen_new_model(torch.load('best.pt'))\n",
    "reg_model.to('cuda')\n",
    "reg_model.eval()\n",
    "img = Image.open(\"1.jpg\").convert(\"RGB\")\n",
    "img.show()\n",
    "img = data_transforms(img)\n",
    "img = torch.unsqueeze(img, dim=0)\n",
    "img = img.to(device)\n",
    "pred = reg_model(img)\n",
    "print(pred[0][0].item())\n",
    "pred = round(pred[0][0].item())\n",
    "print(pred)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mise en commun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_set = set(det_model.names.values())\n",
    "common = dict(zip(det_class_s, reg_s))\n",
    "results={x:0 for x in label_set}\n",
    "for i in range(len(det_class_s)):\n",
    "    results[det_class_s[i]]+=reg_s[i]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not save:\n",
    "    shutil.rmtree('tmp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
