{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook servant à faire l'augmentation de données du jeu de données de détection et à créer le jeu de données de classification si souhaité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 2.0.0 (you have 1.4.7). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import albumentations as A\n",
    "\n",
    "import json\n",
    "import yaml\n",
    "\n",
    "from glob import glob\n",
    "from re import sub\n",
    "from random import randrange\n",
    "import os\n",
    "from PIL import Image\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation des chemins utilisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_only = False # Si True créer un jeu de données \"detections only\" avec pour seul classe \"roll\"\n",
    "\n",
    "detection_class = True # Si True créer un jeu de données \"detection and classification\"\n",
    "\n",
    "classification = False # Si True créer un jeu de données de classification (change detection_class = True)\n",
    "\n",
    "name = 'front1' # Les dossiers finaux seront detection_dataset_<name>, detection_only_dataset_<name> et classification_dataset_<name>\n",
    "\n",
    "'''\n",
    "num_aug: int\n",
    "Le nombre d'images crée par la première transformation pour chaque image source\n",
    "Attention, il y a une étape qui fait l'image miroir de toutes les images\n",
    "Au final on a (nb_img_src * (num_aug + 1)) * 2 images dans le dossier de sortie\n",
    "'''\n",
    "num_aug = 6\n",
    "\n",
    "'''\n",
    "src_dir: str\n",
    "Dossier source avec sous dossiers \"images\" et \"labels\" et fichier notes.json\n",
    "'''\n",
    "src_dir = r\".\\dataset\\frontview1\"\n",
    "\n",
    "'''\n",
    "det_cls_res_path: str\n",
    "Dossier de sortie\n",
    "\n",
    "det_cls_res_path\n",
    "|- train\n",
    "|   |- images\n",
    "|   |   |- img1.jpg\n",
    "|   |   |- img2.jpg\n",
    "|   |   |- ...\n",
    "|   |- labels\n",
    "|       |- img1.txt\n",
    "|       |- img2.txt\n",
    "|       |- ...\n",
    "|- val\n",
    "|   |- images\n",
    "|   |   |- img1.jpg\n",
    "|   |   |- img2.jpg\n",
    "|   |   |- ...\n",
    "|   |- labels\n",
    "|       |- img1.txt\n",
    "|       |- img2.txt\n",
    "|       |- ...\n",
    "|- test\n",
    "|   |- ...\n",
    "|- data.yaml\n",
    "'''\n",
    "det_cls_res_path = \"detection_dataset_\" + name\n",
    "\n",
    "'''\n",
    "det_only_res_path: str\n",
    "Dossier de sortie\n",
    "\n",
    "det_cls_res_path\n",
    "|- train\n",
    "|   |- images\n",
    "|   |   |- img1.jpg\n",
    "|   |   |- img2.jpg\n",
    "|   |   |- ...\n",
    "|   |- labels\n",
    "|       |- img1.txt\n",
    "|       |- img2.txt\n",
    "|       |- ...\n",
    "|- val\n",
    "|   |- images\n",
    "|   |   |- img1.jpg\n",
    "|   |   |- img2.jpg\n",
    "|   |   |- ...\n",
    "|   |- labels\n",
    "|       |- img1.txt\n",
    "|       |- img2.txt\n",
    "|       |- ...\n",
    "|- test\n",
    "|   |- ...\n",
    "|- data.yaml\n",
    "'''\n",
    "det_only_res_path = \"detection_only_dataset_\" + name\n",
    "\n",
    "'''\n",
    "cls_res_path: str\n",
    "Dossier de sortie avec l'oganisation suivante:\n",
    "\n",
    "cls_res_path\n",
    "|- data\n",
    "    |- train\n",
    "    |   |- class 1\n",
    "    |   |   |- img 1\n",
    "    |   |   |- img 2\n",
    "    |   |   |- ...\n",
    "    |   |- class 2\n",
    "    |   |   |- ...\n",
    "    |   |...\n",
    "    |- val\n",
    "    |   |- class 1\n",
    "    |   |   |-...\n",
    "    |   |- ...\n",
    "    |- test\n",
    "        |- ...\n",
    "'''\n",
    "cls_res_path = \"classification_dataset_\" + name\n",
    "\n",
    "if classification:\n",
    "    detection_class = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions de visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOX_COLOR = (255, 0, 0) # Red\n",
    "TEXT_COLOR = (255, 255, 255) # White\n",
    "\n",
    "\n",
    "def visualize_bbox(img, bbox, class_name, color=BOX_COLOR, thickness=10):\n",
    "    \"\"\"Ajoute le boite encadrante à l'image\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Image source\n",
    "        bbox (list: int(x,y,w,h)): Coordonnées de la boite encadrante\n",
    "        class_name (str): Nom de la classe\n",
    "        color (tuple: int, optional): Couleur de la boite. Defaults to BOX_COLOR.\n",
    "        thickness (int, optional): Epaisseur de la boite. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Image avec la boite encadrante\n",
    "    \"\"\"\n",
    "    x_c, y_c, w, h = bbox\n",
    "    height, width, _ = img.shape\n",
    "    x_min, x_max, y_min, y_max = int((x_c - w/2)*width), int((x_c + w/2)*width), int((y_c - h/2)*height), int((y_c + h/2)*height)\n",
    "\n",
    "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)\n",
    "\n",
    "    ((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)\n",
    "    cv2.rectangle(img, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), BOX_COLOR, -1)\n",
    "    cv2.putText(\n",
    "        img,\n",
    "        text=class_name,\n",
    "        org=(x_min, y_min - int(0.3 * text_height)),\n",
    "        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        fontScale=0.35,\n",
    "        color=TEXT_COLOR,\n",
    "        lineType=cv2.LINE_AA,\n",
    "    )\n",
    "    return img\n",
    "\n",
    "\n",
    "def visualize(image, bboxes, category_ids, category_id_to_name, ax = None):\n",
    "    \"\"\"Affiche l'image avec ses boites encadrantes\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): Image source\n",
    "        bboxes (list: list: int): Liste des boites encadrantes\n",
    "        category_ids (list: int): Liste des indice de classe des boites\n",
    "        category_id_to_name (list: str): Liste de conversion indice/nom de classe\n",
    "        ax (plt.axes, optional): Position dans la figure matplotlib. Defaults to None.\n",
    "    \"\"\"\n",
    "    img = image.copy()\n",
    "    for bbox, category_id in zip(bboxes, category_ids):\n",
    "        class_name = category_id_to_name[category_id]\n",
    "        img = visualize_bbox(img, bbox, class_name)\n",
    "    if ax != None:\n",
    "        ax.imshow(img)\n",
    "    else:\n",
    "        plt.figure(figsize=(12, 12))\n",
    "        #plt.axis('off')\n",
    "        plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation\n",
    "\n",
    "Penser à modifier le chemin d'accès au données source si changements\n",
    "\n",
    "L'augmentation est faite en 2 étapes, une première avec des augmentation non systématiques (c'est à dire qu'elles ont des probabilité de ne pas ce produire) et une deuxième étape avec des augmentation systématiques (miroir entre autre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise en place du dossier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m splits \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mlistdir(src_dir):\n\u001b[0;32m      5\u001b[0m         splits \u001b[38;5;241m.\u001b[39mappend(split)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m detection_class:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# création des dossier et sous dossiers\n",
    "splits = []\n",
    "for split in ['test', 'val', 'train']:\n",
    "    if split in os.listdir(src_dir):\n",
    "        splits .append(split)\n",
    "\n",
    "if detection_class:\n",
    "    try:\n",
    "        os.mkdir(det_cls_res_path)\n",
    "    except OSError as error:  \n",
    "        print(error)\n",
    "    for split in splits:\n",
    "        try:\n",
    "            os.mkdir(os.path.join(det_cls_res_path, split))\n",
    "        except OSError as error:  \n",
    "            print(error)\n",
    "        try:\n",
    "            os.mkdir(os.path.join(det_cls_res_path, split, 'images'))\n",
    "        except OSError as error:  \n",
    "            print(error)\n",
    "        try:\n",
    "            os.mkdir(os.path.join(det_cls_res_path, split, 'labels'))\n",
    "        except OSError as error:  \n",
    "            print(error)\n",
    "\n",
    "if detection_only:\n",
    "    try:\n",
    "        os.mkdir(det_only_res_path)\n",
    "    except OSError as error:  \n",
    "        print(error)\n",
    "    for split in splits:\n",
    "        try:\n",
    "            os.mkdir(os.path.join(det_only_res_path, split))\n",
    "        except OSError as error:  \n",
    "            print(error)\n",
    "        try:\n",
    "            os.mkdir(os.path.join(det_only_res_path, split, 'images'))\n",
    "        except OSError as error:  \n",
    "            print(error)\n",
    "        try:\n",
    "            os.mkdir(os.path.join(det_only_res_path, split, 'labels'))\n",
    "        except OSError as error:  \n",
    "            print(error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copie des données val et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file copied: 100%|██████████| 4/4 [00:00<00:00, 66.52it/s]\n",
      "file copied: 100%|██████████| 4/4 [00:00<00:00, 212.16it/s]\n"
     ]
    }
   ],
   "source": [
    "splits = []\n",
    "for split in ['test', 'val']:\n",
    "    if split in os.listdir(src_dir):\n",
    "        splits .append(split)\n",
    "        \n",
    "if detection_class:\n",
    "    for split in splits:\n",
    "        for kind in ['images', 'labels']:\n",
    "            src_path = os.path.join(src_dir, split, kind)\n",
    "            targ_path = os.path.join(det_cls_res_path, split, kind)\n",
    "            for file in tqdm(os.listdir(src_path), desc = 'file copied'):\n",
    "                shutil.copy2(os.path.join(src_path, file), targ_path)\n",
    "\n",
    "if detection_only:\n",
    "    for split in splits:\n",
    "        img_src_path = os.path.join(src_dir, split, \"images\")\n",
    "        lab_src_path = os.path.join(src_dir, split, \"labels\")\n",
    "        images = glob('*.jpg', dir_fd=img_src_path)\n",
    "        img_only_res_path = os.path.join(det_only_res_path, split, \"images\")\n",
    "        lab_only_res_path = os.path.join(det_only_res_path, split, \"labels\")\n",
    "        for img_name in tqdm(images, desc = 'images copied'):\n",
    "            '''\n",
    "            Lecture des fichiers sources avec récupération des boîtes englobantes\n",
    "            '''\n",
    "            shutil.copy2(os.path.join(img_src_path, img_name), img_only_res_path)\n",
    "            label_name = sub(\"jpg$\", \"txt\", img_name)\n",
    "            with open(os.path.join(lab_src_path, label_name), \"r\") as label_file:\n",
    "                new_label_file = open(os.path.join(lab_only_res_path, label_name), 'w')\n",
    "                for line in label_file:\n",
    "                    split_line = line.split(' ')\n",
    "                    new_label_file.write('0')\n",
    "                    for i in range(1,5):\n",
    "                        new_label_file.write(' ' + split_line[i])\n",
    "                new_label_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du fichier .yaml pour YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'detection_dataset_front1\\\\data.yaml'\n"
     ]
    }
   ],
   "source": [
    "if detection_class:\n",
    "    data = {}\n",
    "    try:\n",
    "        json_f = open(os.path.join(src_dir,'train', \"notes.json\"))\n",
    "        json_data = json.load(json_f)\n",
    "\n",
    "        yaml_f = open(os.path.join(det_cls_res_path, \"data.yaml\"), 'w')\n",
    "        names = {}\n",
    "\n",
    "        # cat2name sert à lier l'indice de la classe à son nom\n",
    "        k = 0\n",
    "        cat2name = [0] * len(json_data['categories'])\n",
    "        for category in json_data['categories']:\n",
    "            names[category['id']] = category['name']\n",
    "            cat2name[k] = category['name']\n",
    "            k += 1\n",
    "        \n",
    "        # ajout des champs de données\n",
    "        data['names'] = names\n",
    "        data['nc'] = len(json_data['categories'])\n",
    "        data['train'] =\"./train/images\"\n",
    "        data['val'] = \"./val/images\"\n",
    "        data['test'] = \"./test/images\"\n",
    "\n",
    "        # écriture dans le fichier yaml\n",
    "        yaml.dump(data, yaml_f, default_flow_style=False, allow_unicode=True)\n",
    "\n",
    "        # fermeture des fichiers\n",
    "        json_f.close()\n",
    "        yaml_f.close()\n",
    "\n",
    "    except IOError as error:\n",
    "        print(error)\n",
    "\n",
    "if detection_only:\n",
    "    data = {}\n",
    "    try:\n",
    "        json_f = open(os.path.join(src_dir,'train', \"notes.json\"))\n",
    "        json_data = json.load(json_f)\n",
    "\n",
    "        yaml_f = open(os.path.join(det_only_res_path, \"data.yaml\"), 'w')\n",
    "        names = {}\n",
    "\n",
    "\n",
    "        names['0'] = 'Roll'\n",
    "        \n",
    "        # ajout des champs de données\n",
    "        data['names'] = names\n",
    "        data['nc'] = 1\n",
    "        data['train'] =\"./train/images\"\n",
    "        data['val'] = \"./val/images\"\n",
    "        data['test'] = \"./test/images\"\n",
    "\n",
    "        # écriture dans le fichier yaml\n",
    "        yaml.dump(data, yaml_f, default_flow_style=False, allow_unicode=True)\n",
    "\n",
    "        # fermeture des fichiers\n",
    "        json_f.close()\n",
    "        yaml_f.close()\n",
    "\n",
    "    except IOError as error:\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des données augmentées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dossier cibles\n",
    "img_src_path = os.path.join(src_dir, 'train', 'images')\n",
    "lab_src_path = os.path.join(src_dir, 'train', 'labels')\n",
    "img_cls_res_path = os.path.join(det_cls_res_path, 'train', 'images')\n",
    "lab_cls_res_path = os.path.join(det_cls_res_path, 'train', 'labels')\n",
    "images = glob('*.jpg', dir_fd=img_src_path)\n",
    "\n",
    "img_only_res_path = os.path.join(det_only_res_path, 'train', 'images')\n",
    "lab_only_res_path = os.path.join(det_only_res_path, 'train', 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "images processed: 100%|██████████| 21/21 [00:10<00:00,  2.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# transformations\n",
    "transform1 = A.Compose(\n",
    "    [\n",
    "        # Pixels\n",
    "        A.RandomBrightnessContrast(p=0.2),\n",
    "        A.RandomGamma(p=0.2),\n",
    "        A.ISONoise(p=0.2),\n",
    "        A.GaussNoise(p=0.2),\n",
    "        A.CLAHE(p=0.2), # add contrast\n",
    "        A.RandomSunFlare(src_radius = 100, num_flare_circles_upper= 10, p=0.2), # attention au rayon, si trop grand peut entièrement caché une boite\n",
    "        A.RandomSunFlare(src_radius = 100, num_flare_circles_upper= 10, p=0.2),\n",
    "        A.RandomSunFlare(src_radius = 100, num_flare_circles_upper= 10, p=0.2), # plusieur pour avoir different angles (ils se forment en ligne)\n",
    "        \n",
    "        # Spatial\n",
    "        A.BBoxSafeRandomCrop(p=0.2),\n",
    "        A.Rotate(limit=(-10, 10), p=0.3), # voir quel angles sont raisonnables\n",
    "        # A.PixelDropout(dropout_prob=0.01 ,p=0.5),\n",
    "    ], bbox_params=A.BboxParams(format='yolo', label_fields=['category_ids']), #dans BbowParams on peut ajouter des paramètres de tailles... utile pour les boites qui deviendraient trop petites\n",
    ")\n",
    "\n",
    "transform2 = A.Compose(\n",
    "    [\n",
    "        A.HorizontalFlip(p=1),\n",
    "    ], bbox_params=A.BboxParams(format='yolo', label_fields=['category_ids']), #dans BbowParams on peut ajouter des paramètres de tailles... utile pour les boites qui deviendraient trop petites\n",
    ")\n",
    "\n",
    "assert(detection_class | detection_only)\n",
    "\n",
    "# augmentation des données\n",
    "for img_name in tqdm(images, desc = 'images processed'):\n",
    "    '''\n",
    "    Lecture des fichiers sources avec récupération des boîtes englobantes\n",
    "    '''\n",
    "    image = cv2.imread(os.path.join(img_src_path, img_name)) # lire l'image\n",
    "    bboxes =[]\n",
    "    category_ids = []\n",
    "    label_name = sub(\"jpg$\", \"txt\", img_name)\n",
    "    with open(os.path.join(lab_src_path, label_name), \"r\") as label_file:\n",
    "        for line in label_file:\n",
    "            split_line = line.split(' ')\n",
    "            bboxes.append([float(split_line[1]), float(split_line[2]), float(split_line[3]), float(split_line[4])])\n",
    "            category_ids.append(int(split_line[0]))\n",
    "    '''\n",
    "    Copier l'image et les labels sources dans le dossier final\n",
    "    '''\n",
    "    if detection_class:\n",
    "        shutil.copy2(os.path.join(img_src_path, img_name), img_cls_res_path)\n",
    "        shutil.copy2(os.path.join(lab_src_path, label_name), lab_cls_res_path)\n",
    "    if detection_only:\n",
    "        shutil.copy2(os.path.join(img_src_path, img_name), img_only_res_path)\n",
    "        new_label_file = open(os.path.join(lab_only_res_path, label_name), 'w')\n",
    "        for bbox in bboxes:\n",
    "            new_label_file.write('0')\n",
    "            for i in range(4):\n",
    "                new_label_file.write(' ' + str(bbox[i]))\n",
    "        new_label_file.close()\n",
    "    '''\n",
    "    Création des images augmentées:\n",
    "        - transformation\n",
    "        - miroir de l'originale\n",
    "        - miroir de la transformée\n",
    "    '''\n",
    "    for ind in range(num_aug):\n",
    "        transformed = transform1(image=image, bboxes=bboxes, category_ids=category_ids)\n",
    "        transformed_mirror = transform2(image=transformed['image'], bboxes=transformed['bboxes'], category_ids=transformed['category_ids'])\n",
    "\n",
    "        # enregistrer nouvelles images et labels\n",
    "        # image transformée\n",
    "        if detection_class:\n",
    "            cv2.imwrite(os.path.join(img_cls_res_path, \"transformed_\" + str(ind) + \"_\" + img_name), transformed['image'])\n",
    "            new_label_file = open(os.path.join(lab_cls_res_path, \"transformed_\" + str(ind) + \"_\" + label_name), 'w')\n",
    "            for line in range(len(transformed['bboxes'])):\n",
    "                new_label_file.write(str(transformed['category_ids'][line]))\n",
    "                for i in range(4):\n",
    "                    new_label_file.write(\" \" + str(transformed['bboxes'][line][i]))\n",
    "                new_label_file.write('\\n')\n",
    "            new_label_file.close()\n",
    "        if detection_only:\n",
    "            cv2.imwrite(os.path.join(img_only_res_path, \"transformed_\" + str(ind) + \"_\" + img_name), transformed['image'])\n",
    "            new_label_file = open(os.path.join(lab_only_res_path, \"transformed_\" + str(ind) + \"_\" + label_name), 'w')\n",
    "            for line in range(len(transformed['bboxes'])):\n",
    "                new_label_file.write('0')\n",
    "                for i in range(4):\n",
    "                    new_label_file.write(\" \" + str(transformed['bboxes'][line][i]))\n",
    "                new_label_file.write('\\n')\n",
    "            new_label_file.close()\n",
    "\n",
    "        # image transformée miroir\n",
    "        if detection_class:\n",
    "            cv2.imwrite(os.path.join(img_cls_res_path, \"transformed_miroir_\" + str(ind) + \"_\" + img_name), transformed_mirror['image'])\n",
    "            new_label_file = open(os.path.join(lab_cls_res_path, \"transformed_miroir_\" + str(ind) + \"_\" + label_name), 'w')\n",
    "            for line in range(len(transformed_mirror['bboxes'])):\n",
    "                new_label_file.write(str(transformed_mirror['category_ids'][line]))\n",
    "                for i in range(4):\n",
    "                    new_label_file.write(\" \" + str(transformed_mirror['bboxes'][line][i]))\n",
    "                new_label_file.write('\\n')\n",
    "            new_label_file.close()\n",
    "        if detection_only:\n",
    "            cv2.imwrite(os.path.join(img_only_res_path, \"transformed_miroir_\" + str(ind) + \"_\" + img_name), transformed_mirror['image'])\n",
    "            new_label_file = open(os.path.join(lab_only_res_path, \"transformed_miroir_\" + str(ind) + \"_\" + label_name), 'w')\n",
    "            for line in range(len(transformed_mirror['bboxes'])):\n",
    "                new_label_file.write('0')\n",
    "                for i in range(4):\n",
    "                    new_label_file.write(\" \" + str(transformed_mirror['bboxes'][line][i]))\n",
    "                new_label_file.write('\\n')\n",
    "            new_label_file.close()\n",
    "\n",
    "    # enregistrer image miroir\n",
    "    mirror = transform2(image=image, bboxes=bboxes, category_ids=category_ids)\n",
    "    if detection_class:\n",
    "        cv2.imwrite(os.path.join(img_cls_res_path, \"miroir_\" + img_name), mirror['image'])\n",
    "        new_label_file = open(os.path.join(lab_cls_res_path,\"miroir_\" + label_name), 'w')\n",
    "        for line in range(len(mirror['bboxes'])):\n",
    "            new_label_file.write(str(mirror['category_ids'][line]))\n",
    "            for i in range(4):\n",
    "                new_label_file.write(\" \" + str(mirror['bboxes'][line][i]))\n",
    "            new_label_file.write('\\n')\n",
    "        new_label_file.close()\n",
    "    if detection_only:\n",
    "        cv2.imwrite(os.path.join(img_only_res_path, \"miroir_\" + img_name), mirror['image'])\n",
    "        new_label_file = open(os.path.join(lab_only_res_path, \"miroir_\" + label_name), 'w')\n",
    "        for line in range(len(mirror['bboxes'])):\n",
    "            new_label_file.write('0')\n",
    "            for i in range(4):\n",
    "                new_label_file.write(\" \" + str(mirror['bboxes'][line][i]))\n",
    "            new_label_file.write('\\n')\n",
    "        new_label_file.close()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data augmentation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimages = glob(\\'*.jpg\\', dir_fd=img_cls_res_path)\\nnum_images = len(images)\\n\\nnum_grids = math.ceil(num_images / 9)\\nfor grid in range(num_grids):\\n    fig, axs = plt.subplots(3, 3, figsize=(20, 20))  # Create a 3x3 grid of subplots\\n    fig, axs2 = plt.subplots(3, 3, figsize=(15, 15))  # Create a 3x3 grid of subplots\\n    grid_image_paths = images[grid * 9 : (grid + 1) * 9]\\n\\n    for ax, img_name in zip(axs.flatten(), grid_image_paths):\\n        image = cv2.imread(img_cls_res_path + \\'/\\' + img_name)\\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\\n        ax.imshow(image)\\n        ax.axis(\"off\")\\n\\n    for ax, img_name in zip(axs2.flatten(), grid_image_paths):\\n        image = cv2.imread(img_cls_res_path + \\'/\\' + img_name)\\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\\n        bboxes =[]\\n        category_ids =[]\\n        label_name = sub(\"jpg$\", \"txt\", img_name)\\n        with open(lab_cls_res_path + \\'/\\' + label_name, \"r\") as label_file:\\n            for line in label_file:\\n                split_line = line.split(\\' \\')\\n                bboxes.append([float(split_line[1]), float(split_line[2]), float(split_line[3]), float(split_line[4])])\\n                category_ids.append(int(split_line[0]))\\n        visualize(image, bboxes, category_ids, cat2name, ax)\\n        ax.axis(\"off\")\\n\\n    plt.tight_layout()\\n    plt.show()'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "images = glob('*.jpg', dir_fd=img_cls_res_path)\n",
    "num_images = len(images)\n",
    "\n",
    "num_grids = math.ceil(num_images / 9)\n",
    "for grid in range(num_grids):\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(20, 20))  # Create a 3x3 grid of subplots\n",
    "    fig, axs2 = plt.subplots(3, 3, figsize=(15, 15))  # Create a 3x3 grid of subplots\n",
    "    grid_image_paths = images[grid * 9 : (grid + 1) * 9]\n",
    "\n",
    "    for ax, img_name in zip(axs.flatten(), grid_image_paths):\n",
    "        image = cv2.imread(img_cls_res_path + '/' + img_name)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        ax.imshow(image)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    for ax, img_name in zip(axs2.flatten(), grid_image_paths):\n",
    "        image = cv2.imread(img_cls_res_path + '/' + img_name)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        bboxes =[]\n",
    "        category_ids =[]\n",
    "        label_name = sub(\"jpg$\", \"txt\", img_name)\n",
    "        with open(lab_cls_res_path + '/' + label_name, \"r\") as label_file:\n",
    "            for line in label_file:\n",
    "                split_line = line.split(' ')\n",
    "                bboxes.append([float(split_line[1]), float(split_line[2]), float(split_line[3]), float(split_line[4])])\n",
    "                category_ids.append(int(split_line[0]))\n",
    "        visualize(image, bboxes, category_ids, cat2name, ax)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data health check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 21 images dans le dossier source:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cat2name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# info source\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIl y a \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(labels_src)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m images dans le dossier source:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m label_count \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mcat2name\u001b[49m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m labels_src:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(lab_src_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m fname, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m label_file:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cat2name' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "labels_src = glob('*.txt', dir_fd=lab_src_path)\n",
    "labels_augment = glob('*.txt', dir_fd=lab_cls_res_path)\n",
    "img_src = glob('*.jpg', dir_fd=img_src_path)\n",
    "img_augment = glob('*.jpg', dir_fd=img_cls_res_path)\n",
    "\n",
    "# info source\n",
    "print(\"Il y a \" + str(len(labels_src)) + \" images dans le dossier source:\")\n",
    "\n",
    "label_count = [0] * len(cat2name)\n",
    "\n",
    "for fname in labels_src:\n",
    "    with open(lab_src_path + '/' + fname, \"r\") as label_file:\n",
    "        for line in label_file:\n",
    "            split_line = line.split(' ')\n",
    "            label_count[int(split_line[0])] += 1\n",
    "\n",
    "for i in range(len(cat2name)):\n",
    "    print(cat2name[i], \" a \", label_count[i], \" instances\")\n",
    "\n",
    "# info augmenté\n",
    "print(\"------------------------------------------\\nIl y a \" + str(len(labels_augment)) + \" images dans le dossier augmenté:\")\n",
    "\n",
    "label_count = [0] * len(cat2name)\n",
    "\n",
    "for fname in labels_augment:\n",
    "    with open(lab_cls_res_path + '/' + fname, \"r\") as label_file:\n",
    "        for line in label_file:\n",
    "            split_line = line.split(' ')\n",
    "            label_count[int(split_line[0])] += 1\n",
    "\n",
    "for i in range(len(cat2name)):\n",
    "    print(cat2name[i], \" a \", label_count[i], \" instances\")\n",
    "\n",
    "# info dimension moyenne images\n",
    "print(\"------------------------------------------\\nLes dimension moyennes du jeu source sont:\")\n",
    "mean_w = 0\n",
    "mean_h = 0\n",
    "\n",
    "for fname in img_src:\n",
    "    with Image.open(img_src_path + '/' + fname) as img:\n",
    "        w, h = img.size\n",
    "        mean_w += w\n",
    "        mean_h += h\n",
    "mean_w /= len(img_src)\n",
    "mean_h /= len(img_src)\n",
    "\n",
    "print(\"mean width = \", mean_w)\n",
    "print(\"mean heigh = \", mean_h)\n",
    "\n",
    "print(\"------------------------------------------\\nLes dimension moyennes du jeu augmenté sont:\")\n",
    "mean_w = 0\n",
    "mean_h = 0\n",
    "\n",
    "for fname in img_augment:\n",
    "    with Image.open(img_cls_res_path + '/' + fname) as img:\n",
    "        w, h = img.size\n",
    "        mean_w += w\n",
    "        mean_h += h\n",
    "mean_w /= len(img_augment)\n",
    "mean_h /= len(img_augment)\n",
    "\n",
    "print(\"mean width = \", mean_w)\n",
    "print(\"mean heigh = \", mean_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Génération du Dataset \"classification\"\n",
    "\n",
    "<span style=\"color: red\"> Attention </span>: Si il y a un problème lors de l'entraînement, vérifier:\n",
    "- si il y a au <span style=\"color: red\"> minimum </span> 2 splits (\"train\" et \"val\" ou \"train\" et \"test\")\n",
    "- si les split créés on au <span style=\"color: red\"> minimum </span> une image par classe\n",
    "- le champs data du model YOLO pointe vers le dossier contenant les splits (\"train\", ...)\n",
    "\n",
    "Le fichier <span style=\"color: blue\"> data.yaml </span> n'est ici qu'<span style=\"color: blue\"> informatif </span> et n'est pas utilisé par YOLO!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# don't go beyond here with Run All\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m classification\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# don't go beyond here with Run All\n",
    "assert classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation des chemins utilisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "src_dir: str\n",
    "Dossier source avec sous dossiers \"images\" et \"labels\" et fichier notes.json\n",
    "'''\n",
    "src_dir = det_cls_res_path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dossier dataset\n",
    "try:\n",
    "    os.mkdir(cls_res_path)\n",
    "except OSError as error:  \n",
    "    print(error)\n",
    "\n",
    "# cropping par split\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    img_src_path = src_dir + \"/\" + split + \"/images\"\n",
    "    lab_src_path = src_dir + \"/\" + split + \"/labels\"\n",
    "    images = glob('*.jpg', dir_fd=img_src_path)\n",
    "    if len(images)==0:\n",
    "        continue\n",
    "    # création des dossiers du splt\n",
    "    try:\n",
    "        os.mkdir(cls_res_path + \"/\" + split)\n",
    "    except OSError as error:  \n",
    "        print(error)\n",
    "    for classname in cat2name:\n",
    "        try:\n",
    "            os.mkdir(cls_res_path + '/' + split + '/' + classname)\n",
    "        except OSError as error:  \n",
    "            print(error)\n",
    "\n",
    "    img_res_path = cls_res_path + '/' + split\n",
    "\n",
    "    for img_name in tqdm(images, desc = split):\n",
    "        img_src = cv2.imread(img_src_path + '/' + img_name)\n",
    "        img_h, img_w, nb_chan = img_src.shape\n",
    "        bboxes =[]\n",
    "        category_ids =[]\n",
    "        label_name = sub(\"jpg$\", \"txt\", img_name)\n",
    "        # récupération des informations\n",
    "        with open(lab_src_path + '/' + label_name, \"r\") as label_file:\n",
    "            for line in label_file:\n",
    "                split_line = line.split(' ')\n",
    "                bboxes.append([int(float(split_line[1])*img_w), int(float(split_line[2])*img_h), int(float(split_line[3])*img_w), int(float(split_line[4])*img_h)])\n",
    "                category_ids.append(int(split_line[0]))\n",
    "        # cropping et enregistrement des images\n",
    "        for k, instance in enumerate(zip(bboxes, category_ids)):\n",
    "            bbox, cat_id = instance\n",
    "            '''\n",
    "            le repère de cv2 est \n",
    "            0/0---X--->\n",
    "            |\n",
    "            |\n",
    "            Y\n",
    "            |\n",
    "            |\n",
    "            v\n",
    "            '''\n",
    "            xmin = bbox[0] - bbox[2]//2\n",
    "            xmax = bbox[0] + bbox[2]//2\n",
    "            ymin = bbox[1] - bbox[3]//2\n",
    "            ymax = bbox[1] + bbox[3]//2\n",
    "            crop_img = img_src[ymin:ymax, xmin:xmax] # [y, x]\n",
    "            cat_name = cat2name[cat_id]\n",
    "            crop_img_name = img_res_path + '/' + cat_name + '/cropped_image' + str(k) + '_' + img_name\n",
    "            cv2.imwrite(crop_img_name, crop_img)\n",
    "\n",
    "# yaml file\n",
    "# ajout des champs de données\n",
    "data = {}\n",
    "data['path'] = cls_res_path\n",
    "data['names'] = cat2name\n",
    "data['nc'] = len(cat2name)\n",
    "data['train'] =\"train\"\n",
    "data['val'] = \"val\"\n",
    "data['test'] = \"test\"\n",
    "\n",
    "try:\n",
    "    yaml_f = open(cls_res_path + \"/data.yaml\", 'w')\n",
    "\n",
    "    # écriture dans le fichier yaml\n",
    "    yaml.dump(data, yaml_f, default_flow_style=False, allow_unicode=True)\n",
    "\n",
    "    # fermeture des fichiers\n",
    "    yaml_f.close()\n",
    "\n",
    "except IOError as error:\n",
    "    print(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension moyenne des images de classification:\n",
      "------------------------------------------\n",
      "train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image in 3G: 0it [00:00, ?it/s]:00<?, ?it/s]\n",
      "image in 4G: 0it [00:00, ?it/s]\n",
      "image in B4: 0it [00:00, ?it/s]\n",
      "image in B8: 0it [00:00, ?it/s]\n",
      "train: 100%|██████████| 4/4 [00:00<00:00, 177.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No image in train split!\n",
      "------------------------------------------\n",
      "val:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image in 3G: 0it [00:00, ?it/s]0<?, ?it/s]\n",
      "image in 4G: 0it [00:00, ?it/s]\n",
      "image in B4: 0it [00:00, ?it/s]\n",
      "image in B8: 0it [00:00, ?it/s]\n",
      "val: 100%|██████████| 4/4 [00:00<00:00, 188.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No image in val split!\n",
      "------------------------------------------\n",
      "test:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image in 3G: 0it [00:00, ?it/s]00<?, ?it/s]\n",
      "image in 4G: 0it [00:00, ?it/s]\n",
      "image in B4: 0it [00:00, ?it/s]\n",
      "image in B8: 0it [00:00, ?it/s]\n",
      "test: 100%|██████████| 4/4 [00:00<00:00, 170.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No image in test split!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimension moyenne des images de classification:\")\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    print(\"------------------------------------------\\n\" + split + ':')\n",
    "    mean_w = 0\n",
    "    mean_h = 0\n",
    "    max_w, min_w, max_h, min_h = 0, math.inf , 0, math.inf\n",
    "    nb_img = 0\n",
    "\n",
    "    split_path = cls_res_path + '/' + split\n",
    "\n",
    "    for label in tqdm(cat2name, desc = split):\n",
    "        fnames = glob('*.jpg', dir_fd=split_path + '/' + label)\n",
    "        nb_img += len(fnames)\n",
    "        for fname in tqdm(fnames, desc = 'image in '+label):\n",
    "            with Image.open(split_path + '/' + label + '/' + fname) as img:\n",
    "                w, h = img.size\n",
    "                mean_w += w\n",
    "                mean_h += h\n",
    "                if w > max_w:\n",
    "                    max_w = w\n",
    "                if w < min_w:\n",
    "                    min_w = w\n",
    "                if h > max_h:\n",
    "                    max_h = h\n",
    "                if h < min_h:\n",
    "                    min_h = h\n",
    "    if nb_img != 0:            \n",
    "        mean_w /= nb_img\n",
    "        mean_h /= nb_img\n",
    "\n",
    "        print(\"\\nmean width = \", mean_w)\n",
    "        print(\"mean heigh = \", mean_h)\n",
    "        print(\"max width: \", max_w)\n",
    "        print(\"min width: \", min_w)\n",
    "        print(\"max heigh: \", max_h)\n",
    "        print(\"min heigh: \", min_h)\n",
    "        print(\"number of images: \", nb_img)\n",
    "    else:\n",
    "        print(\"No image in \" + split + \" split!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
